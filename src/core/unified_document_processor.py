"""
Processador Unificado de Documentos para Licita√ß√µes
Combina processamento local e nuvem com m√°xima flexibilidade
"""

import os
import requests
import zipfile
import tempfile
import hashlib
import magic
import logging
import uuid
import json
from pathlib import Path
from typing import List, Dict, Optional, Any
from psycopg2.extras import DictCursor
import PyPDF2
import io
from datetime import datetime
from supabase import create_client, Client
from services.storage_service import StorageService
from rag.advanced_text_extractor import AdvancedTextExtractor

# Configurar logging
logger = logging.getLogger(__name__)

class UnifiedDocumentProcessor:
    """Processador unificado para documentos de licita√ß√µes"""
    
    def __init__(self, db_manager, supabase_url: str, supabase_key: str):
        self.db_manager = db_manager
        self.storage_service = StorageService(supabase_url, supabase_key)
        
        # Nome do bucket
        self.bucket_name = "licitacao-documents"
        
        # Diret√≥rio tempor√°rio apenas para processamento
        self.temp_path = Path('./storage/temp')
        self.temp_path.mkdir(parents=True, exist_ok=True)
        
        # Extens√µes aceitas
        self.allowed_extensions = {'.pdf', '.doc', '.docx', '.txt', '.rtf', '.odt', '.zip'}
        
        # üÜï Inicializar extrator avan√ßado de texto
        self.text_extractor = AdvancedTextExtractor()
        logger.info(f"üîß Extrator de texto inicializado: {self.text_extractor.get_extractor_status()}")
        
        # Garantir bucket
        self._ensure_bucket_exists()
    
    def _ensure_bucket_exists(self):
        """
        Garante que o bucket existe (assume que j√° foi criado via configura√ß√£o)
        """
        try:
            # Ao inv√©s de listar buckets (que requer permiss√µes especiais),
            # simplesmente testar se conseguimos listar arquivos no bucket
            files_test = self.storage_service.list("")  # Lista raiz do bucket
            logger.info(f"‚úÖ Bucket '{self.bucket_name}' acess√≠vel e funcionando")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Aviso ao testar bucket (normal com ANON_KEY): {e}")
            logger.info(f"üì¶ Assumindo que bucket '{self.bucket_name}' existe (configurado externamente)")
    
    # ================================
    # PASSOS 1, 2, 3 - IGUAIS AOS ANTERIORES
    # ================================
    
    def extrair_info_licitacao(self, licitacao_id: str) -> Optional[Dict]:
        """PASSO 1: Extrai informa√ß√µes da licita√ß√£o do banco"""
        try:
            logger.info(f"üîç PASSO 1: Buscando licita√ß√£o: {licitacao_id}")
            
            with self.db_manager.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    query = """
                        SELECT id, pncp_id, orgao_cnpj, ano_compra, sequencial_compra, 
                               objeto_compra, status, modalidade_nome, modalidade_id,
                               valor_total_estimado, uf, data_publicacao, data_abertura_proposta,
                               data_encerramento_proposta, orgao_entidade, unidade_orgao
                        FROM licitacoes 
                        WHERE id = %s OR pncp_id = %s
                    """
                    
                    cursor.execute(query, (licitacao_id, licitacao_id))
                    result = cursor.fetchone()
                    
                    if result:
                        logger.info(f"‚úÖ PASSO 1 OK: Licita√ß√£o encontrada")
                        return dict(result)
                    else:
                        logger.error(f"‚ùå PASSO 1 FALHOU: Licita√ß√£o n√£o encontrada")
                        return None
                
        except Exception as e:
            logger.error(f"‚ùå ERRO PASSO 1: {e}")
            return None
    
    def verificar_documentos_existem(self, licitacao_id: str) -> bool:
        """PASSO 2: Verifica se documentos j√° foram processados"""
        try:
            logger.info(f"üîç PASSO 2: Verificando documentos existentes")
            
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(
                        "SELECT COUNT(*) FROM documentos_licitacao WHERE licitacao_id = %s", 
                        (licitacao_id,)
                    )
                    count = cursor.fetchone()[0]
                    
                    exists = count > 0
                    if exists:
                        logger.info(f"‚úÖ PASSO 2: {count} documentos j√° existem")
                    else:
                        logger.info(f"‚úÖ PASSO 2: Nenhum documento existente")
                    
                    return exists
                
        except Exception as e:
            logger.error(f"‚ùå ERRO PASSO 2: {e}")
            return False
    
    def construir_url_documentos(self, licitacao_info: Dict) -> str:
        """PASSO 3: Constr√≥i URL da API PNCP"""
        try:
            logger.info(f"üîß PASSO 3: Construindo URL da API")
            
            cnpj = licitacao_info['orgao_cnpj']
            ano = licitacao_info['ano_compra']
            sequencial = licitacao_info['sequencial_compra']
            
            url = f"https://pncp.gov.br/pncp-api/v1/orgaos/{cnpj}/compras/{ano}/{sequencial}/arquivos"
            
            logger.info(f"‚úÖ PASSO 3 OK: URL constru√≠da")
            return url
            
        except KeyError as e:
            logger.error(f"‚ùå ERRO PASSO 3: Campo ausente: {e}")
            raise
    
    # ================================
    # PASSO 4 - PROCESSAMENTO FLEX√çVEL
    # ================================
    
    def processar_resposta_pncp(self, url: str, licitacao_id: str) -> Optional[List[Dict]]:
        """PASSO 4: Processa resposta da API PNCP (flex√≠vel para JSON ou ZIP)"""
        try:
            logger.info(f"üåê PASSO 4: Fazendo requisi√ß√£o para API PNCP")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/json, application/zip, */*'
            }
            
            response = requests.get(url, headers=headers, timeout=60)
            response.raise_for_status()
            
            content_type = response.headers.get('content-type', '').lower()
            logger.info(f"üì• Content-Type recebido: {content_type}")
            
            # Detectar tipo de resposta
            if 'json' in content_type:
                logger.info(f"üìã Resposta JSON: Lista de documentos")
                return self._processar_lista_documentos(response.json(), licitacao_id)
            
            elif 'zip' in content_type or 'application/octet-stream' in content_type:
                logger.info(f"üì¶ Resposta ZIP: Arquivo compactado")
                return self._processar_arquivo_zip(response.content, licitacao_id)
            
            else:
                logger.warning(f"‚ö†Ô∏è Tipo de resposta n√£o reconhecido: {content_type}")
                # Tentar como JSON primeiro
                try:
                    data = response.json()
                    return self._processar_lista_documentos(data, licitacao_id)
                except:
                    # Tentar como ZIP
                    return self._processar_arquivo_zip(response.content, licitacao_id)
            
        except Exception as e:
            logger.error(f"‚ùå ERRO PASSO 4: {e}")
            return None
    
    def _processar_lista_documentos(self, documentos_lista: List[Dict], licitacao_id: str) -> List[Dict]:
        """Processa lista JSON de documentos"""
        try:
            if not isinstance(documentos_lista, list) or len(documentos_lista) == 0:
                logger.warning("‚ö†Ô∏è Lista de documentos vazia")
                return []
            
            logger.info(f"üìÑ Processando {len(documentos_lista)} documentos da lista")
            
            documentos_processados = []
            
            for i, doc_info in enumerate(documentos_lista):
                try:
                    doc_url = doc_info.get('url') or doc_info.get('uri')
                    doc_titulo = doc_info.get('titulo', f'documento_{i+1}')
                    tipo_documento = doc_info.get('tipoDocumentoNome', 'Documento')
                    sequencial_documento = doc_info.get('sequencialDocumento', i + 1)
                    
                    if not doc_url:
                        logger.warning(f"‚ö†Ô∏è URL n√£o encontrada para: {doc_titulo}")
                        continue
                    
                    logger.info(f"üì• Baixando {i+1}/{len(documentos_lista)}: {doc_titulo} ({tipo_documento})")
                    
                    # üîß CORRE√á√ÉO: Headers mais espec√≠ficos para garantir download do PDF
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                        'Accept': 'application/pdf, application/octet-stream, */*',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'Connection': 'keep-alive'
                    }
                    
                    # Baixar arquivo individual
                    doc_response = requests.get(doc_url, headers=headers, timeout=120, stream=True)
                    doc_response.raise_for_status()
                    
                    # üîß VERIFICA√á√ÉO: Confirmar que o conte√∫do √© realmente um arquivo
                    content_type = doc_response.headers.get('content-type', '').lower()
                    content_length = doc_response.headers.get('content-length', '0')
                    
                    logger.info(f"üìã Content-Type: {content_type}, Size: {content_length} bytes")
                    
                    # Se recebeu ao inv√©s de arquivo, logar erro detalhado
                    if 'text/html' in content_type:
                        logger.error(f"‚ùå URL retornou HTML ao inv√©s de arquivo: {doc_url}")
                        logger.error(f"üîç Response preview: {doc_response.text[:200]}...")
                        continue
                    
                    # A detec√ß√£o de ZIP agora √© feita em _processar_arquivo_individual
                    
                    # üîß CORRE√á√ÉO: Criar nome mais descritivo
                    nome_arquivo = f"{sequencial_documento:03d}_{doc_titulo}_{tipo_documento}"
                    
                    # Processar arquivo (pode retornar m√∫ltiplos documentos se for ZIP)
                    documentos_resultado = self._processar_arquivo_individual(
                        doc_response.content,
                        nome_arquivo,
                        licitacao_id,
                        sequencial_documento,
                        doc_info
                    )
                    
                    if documentos_resultado:
                        documentos_processados.extend(documentos_resultado)
                        logger.info(f"‚úÖ {len(documentos_resultado)} documento(s) processado(s): {nome_arquivo}")
                    else:
                        logger.error(f"‚ùå Falha ao processar: {nome_arquivo}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Erro ao processar documento {i+1}: {e}")
                    # Log mais detalhado do erro
                    import traceback
                    logger.error(f"üîç Traceback: {traceback.format_exc()}")
                    continue
            
            logger.info(f"‚úÖ {len(documentos_processados)} de {len(documentos_lista)} documentos processados com sucesso")
            return documentos_processados
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar lista de documentos: {e}")
            import traceback
            logger.error(f"üîç Traceback: {traceback.format_exc()}")
            return []
    
    def _processar_arquivo_zip(self, zip_content: bytes, licitacao_id: str) -> List[Dict]:
        """Processa arquivo ZIP com m√∫ltiplos documentos"""
        try:
            logger.info(f"üì¶ Processando arquivo ZIP ({len(zip_content)} bytes)")
            
            # Salvar ZIP temporariamente
            temp_zip_path = self.temp_path / f"temp_{licitacao_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
            
            with open(temp_zip_path, 'wb') as f:
                f.write(zip_content)
            
            documentos_processados = []
            extract_dir = None
            
            try:
                # Extrair ZIP
                extract_dir = self.temp_path / f"extracted_{licitacao_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                extract_dir.mkdir(exist_ok=True)
                
                with zipfile.ZipFile(temp_zip_path, 'r') as zip_ref:
                    zip_ref.extractall(extract_dir)
                
                # Processar arquivos extra√≠dos
                contador = 1
                for file_path in extract_dir.rglob('*'):
                    if file_path.is_file() and file_path.suffix.lower() in self.allowed_extensions:
                        
                        # Ignorar arquivos de sistema
                        if file_path.name.startswith('.') or '__MACOSX' in str(file_path):
                            continue
                        
                        logger.info(f"üìÑ Processando arquivo {contador}: {file_path.name}")
                        
                        # Ler conte√∫do do arquivo
                        with open(file_path, 'rb') as f:
                            arquivo_content = f.read()
                        
                        # Processar arquivo (pode retornar m√∫ltiplos se for ZIP aninhado)
                        documentos_resultado = self._processar_arquivo_individual(
                            arquivo_content,
                            file_path.name,
                            licitacao_id,
                            contador
                        )
                        
                        if documentos_resultado:
                            documentos_processados.extend(documentos_resultado)
                        
                        contador += 1
                
                logger.info(f"‚úÖ {len(documentos_processados)} documentos extra√≠dos do ZIP")
                return documentos_processados
                
            finally:
                # Limpar arquivos tempor√°rios
                if temp_zip_path.exists():
                    temp_zip_path.unlink()
                if extract_dir and extract_dir.exists():
                    import shutil
                    shutil.rmtree(extract_dir, ignore_errors=True)
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar ZIP: {e}")
            return []
    
    def _processar_arquivo_individual(self, 
                                    arquivo_content: bytes, 
                                    nome_original: str, 
                                    licitacao_id: str, 
                                    sequencial: int,
                                    metadata_extra: Dict = None) -> Optional[List[Dict]]:
        """
        Processa um arquivo individual com verifica√ß√£o recursiva de ZIPs
        Retorna lista de documentos (pode ser 1 PDF ou m√∫ltiplos extra√≠dos de ZIP)
        """
        try:
            # üîß VALIDA√á√ÉO: Verificar se o conte√∫do n√£o est√° vazio
            if not arquivo_content or len(arquivo_content) == 0:
                logger.error(f"‚ùå Arquivo vazio ou conte√∫do nulo: {nome_original}")
                return None
            
            # üîß VALIDA√á√ÉO: Verificar se n√£o √© HTML (erro comum)
            if arquivo_content.startswith(b'<!DOCTYPE') or arquivo_content.startswith(b'<html'):
                logger.error(f"‚ùå Arquivo cont√©m HTML ao inv√©s de dados bin√°rios: {nome_original}")
                logger.error(f"üîç Conte√∫do: {arquivo_content[:200].decode('utf-8', errors='ignore')}...")
                return None
            
            logger.info(f"üìÑ Processando arquivo: {nome_original} ({len(arquivo_content)} bytes)")
            
            # üÜï NOVA L√ìGICA: Verificar se √© ZIP ANTES de salvar no storage
            if self._is_zip_content(arquivo_content):
                logger.info(f"üì¶ ZIP detectado - extraindo recursivamente: {nome_original}")
                return self._extrair_zip_recursivo(arquivo_content, licitacao_id, sequencial, nome_original)
            
            # Se n√£o √© ZIP, processar como arquivo normal (apenas PDFs)
            return self._salvar_arquivo_final(arquivo_content, nome_original, licitacao_id, sequencial, metadata_extra)
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar arquivo {nome_original}: {e}")
            return None

    def _is_zip_content(self, content: bytes) -> bool:
        """Verifica se o conte√∫do √© um ZIP"""
        return (content.startswith(b'PK\x03\x04') or 
                content.startswith(b'PK\x05\x06') or 
                content.startswith(b'PK\x07\x08'))

    def _extrair_zip_recursivo(self, zip_content: bytes, licitacao_id: str, sequencial_base: int, nome_zip: str) -> List[Dict]:
        """
        Extrai ZIP recursivamente at√© encontrar apenas arquivos PDF finais
        """
        try:
            logger.info(f"üîÑ Extra√ß√£o recursiva do ZIP: {nome_zip}")
            
            # Salvar ZIP temporariamente
            temp_zip_path = self.temp_path / f"recursive_{licitacao_id}_{sequencial_base}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
            
            with open(temp_zip_path, 'wb') as f:
                f.write(zip_content)
            
            documentos_finais = []
            extract_dir = None
            
            try:
                # Extrair ZIP
                extract_dir = self.temp_path / f"extracted_recursive_{licitacao_id}_{sequencial_base}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                extract_dir.mkdir(exist_ok=True)
                
                with zipfile.ZipFile(temp_zip_path, 'r') as zip_ref:
                    zip_ref.extractall(extract_dir)
                
                # Processar arquivos extra√≠dos recursivamente
                contador_arquivo = 1
                for file_path in extract_dir.rglob('*'):
                    if file_path.is_file():
                        
                        # Ignorar arquivos de sistema
                        if file_path.name.startswith('.') or '__MACOSX' in str(file_path):
                            continue
                        
                        # Ler conte√∫do do arquivo
                        with open(file_path, 'rb') as f:
                            arquivo_content = f.read()
                        
                        logger.info(f"üîç Analisando arquivo extra√≠do: {file_path.name}")
                        
                        # üÜï VERIFICA√á√ÉO RECURSIVA: Se √© outro ZIP, extrair recursivamente
                        if self._is_zip_content(arquivo_content):
                            logger.info(f"üì¶ ZIP aninhado encontrado, extraindo recursivamente: {file_path.name}")
                            # Usar sequencial composto para ZIPs aninhados
                            subsequencial = int(f"{sequencial_base}{contador_arquivo:02d}")
                            zip_docs = self._extrair_zip_recursivo(arquivo_content, licitacao_id, subsequencial, file_path.name)
                            if zip_docs:
                                documentos_finais.extend(zip_docs)
                        
                        # Se √© PDF, processar e salvar
                        elif self._is_pdf_content(arquivo_content):
                            logger.info(f"üìÑ PDF encontrado, salvando: {file_path.name}")
                            # Usar sequencial composto para PDFs dentro de ZIPs
                            subsequencial = int(f"{sequencial_base}{contador_arquivo:02d}")
                            pdf_docs = self._salvar_arquivo_final(arquivo_content, file_path.name, licitacao_id, subsequencial)
                            if pdf_docs:
                                documentos_finais.extend(pdf_docs)
                        
                        # Se n√£o √© nem ZIP nem PDF, ignorar
                        else:
                            extensao = self._detectar_extensao(arquivo_content, file_path.name)
                            logger.warning(f"‚ö†Ô∏è Arquivo ignorado (apenas PDFs s√£o salvos): {file_path.name} - {extensao}")
                        
                        contador_arquivo += 1
                
                logger.info(f"‚úÖ Extra√ß√£o recursiva conclu√≠da: {len(documentos_finais)} documentos finais extra√≠dos")
                return documentos_finais
                
            finally:
                # Limpar arquivos tempor√°rios
                if temp_zip_path.exists():
                    temp_zip_path.unlink()
                if extract_dir and extract_dir.exists():
                    import shutil
                    shutil.rmtree(extract_dir, ignore_errors=True)
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o recursiva: {e}")
            return []

    def _is_pdf_content(self, content: bytes) -> bool:
        """Verifica se o conte√∫do √© um PDF"""
        return content.startswith(b'%PDF') or b'%PDF' in content[:1000]

    def _salvar_arquivo_final(self, arquivo_content: bytes, nome_original: str, licitacao_id: str, sequencial: int, metadata_extra: Dict = None) -> List[Dict]:
        """
        Salva um arquivo final (n√£o-ZIP) no storage
        Retorna lista com 1 documento
        """
        try:
            # Limpar nome do arquivo
            nome_limpo = self._limpar_nome_arquivo(nome_original)
            
            # Determinar extens√£o e tipo
            extensao = self._detectar_extensao(arquivo_content, nome_limpo)
            
            # üîß FILTRO: S√≥ processar PDFs (ZIPs s√£o tratados separadamente)
            if extensao != '.pdf':
                logger.warning(f"‚ö†Ô∏è Apenas PDFs s√£o salvos no storage: {extensao} - {nome_original}")
                return []
            
            # üîß CORRE√á√ÉO: Se detectou HTML, n√£o processar
            if extensao == '.html':
                logger.error(f"‚ùå Arquivo detectado como HTML - pulando: {nome_original}")
                return []
            
            # Garantir que o nome tenha extens√£o
            if not nome_limpo.endswith(extensao):
                if '.' in nome_limpo:
                    nome_limpo = f"{nome_limpo.split('.')[0]}{extensao}"
                else:
                    nome_limpo = f"{nome_limpo}{extensao}"
            
            # Caminho na nuvem
            cloud_path = f"licitacoes/{licitacao_id}/{sequencial:03d}_{nome_limpo}"
            
            # Upload para Supabase
            logger.info(f"‚òÅÔ∏è Fazendo upload do arquivo final: {cloud_path}")
            
            try:
                # üîß CORRE√á√ÉO: Verificar se arquivo j√° existe
                try:
                    existing = self.storage_service.list(f"licitacoes/{licitacao_id}")
                    file_exists = any(file['name'] == f"{sequencial:03d}_{nome_limpo}" for file in existing)
                    
                    if file_exists:
                        logger.info(f"üìÅ Arquivo j√° existe, usando vers√£o existente: {cloud_path}")
                    else:
                        # Fazer upload normalmente
                        upload_result = self.storage_service.upload(
                            cloud_path, 
                            arquivo_content,
                            content_type=self._get_mime_type(extensao)
                        )
                        
                        if not upload_result:
                            logger.error(f"‚ùå Falha no upload: {nome_original}")
                            return []
                        else:
                            logger.info(f"‚úÖ Upload conclu√≠do: {cloud_path}")
                            
                except Exception as upload_error:
                    # Se erro √© de duplicata, tentar obter URL do arquivo existente
                    if 'Duplicate' in str(upload_error) or 'already exists' in str(upload_error):
                        logger.info(f"üìÅ Arquivo duplicado detectado, usando vers√£o existente: {cloud_path}")
                    else:
                        raise upload_error
                
                # üîß CORRE√á√ÉO: Gerar URL p√∫blica sem query parameters problem√°ticos
                raw_url = self.storage_service.get_public_url(cloud_path)
                
                # Limpar URL removendo query parameters vazios que causam problemas
                if raw_url.endswith('?'):
                    public_url = raw_url[:-1]  # Remove o ? no final
                elif '?' in raw_url and not any(param for param in raw_url.split('?')[1].split('&') if '=' in param):
                    public_url = raw_url.split('?')[0]  # Remove query params vazios
                else:
                    public_url = raw_url
                
                logger.info(f"üìé URL gerada: {public_url}")
                
                # üÜï NOVO: Extrair texto usando extrator avan√ßado
                texto_preview = None
                extraction_result = None
                if extensao == '.pdf':
                    try:
                        logger.info(f"üîÑ Extraindo texto avan√ßado: {nome_original}")
                        extraction_result = self.text_extractor.extract_text_from_bytes(
                            arquivo_content, 
                            nome_original
                        )
                        
                        if extraction_result['success']:
                            # Para preview, pegar s√≥ os primeiros 1000 caracteres
                            texto_preview = extraction_result['text'][:1000]
                            if len(extraction_result['text']) > 1000:
                                texto_preview += "..."
                            
                            logger.info(f"‚úÖ Texto extra√≠do com {extraction_result['extractor_used']} em {extraction_result['extraction_time']:.2f}s")
                        else:
                            logger.warning(f"‚ö†Ô∏è Falha na extra√ß√£o: {extraction_result.get('error', 'Erro desconhecido')}")
                            # Fallback para m√©todo antigo se novo falhar
                            texto_preview = self._extrair_texto_pdf_fallback(arquivo_content)
                    
                    except Exception as e:
                        logger.error(f"‚ùå Erro no extrator avan√ßado: {e}")
                        # Fallback para m√©todo antigo
                        texto_preview = self._extrair_texto_pdf_fallback(arquivo_content)
                
                # Montar documento
                documento = {
                    'licitacao_id': licitacao_id,
                    'titulo': nome_original,
                    'arquivo_nuvem_url': public_url,
                    'tipo_arquivo': self._get_mime_type(extensao),
                    'tamanho_arquivo': len(arquivo_content),
                    'hash_arquivo': hashlib.sha256(arquivo_content).hexdigest(),
                    'texto_preview': texto_preview,
                    'metadata_arquivo': {
                        'nome_original': nome_original,
                        'nome_limpo': nome_limpo,
                        'extensao': extensao,
                        'sequencial': sequencial,
                        'cloud_path': cloud_path,
                        'storage_provider': 'supabase',
                        'bucket_name': self.bucket_name,
                        'processado_em': datetime.now().isoformat(),
                        'is_extracted_from_zip': metadata_extra is not None,
                        # üÜï Metadados da extra√ß√£o de texto
                        'text_extraction': {
                            'extractor_used': extraction_result['extractor_used'] if extraction_result and extraction_result['success'] else None,
                            'extraction_time': extraction_result['extraction_time'] if extraction_result else None,
                            'char_count': extraction_result['char_count'] if extraction_result and extraction_result['success'] else None,
                            'page_count': extraction_result['page_count'] if extraction_result and extraction_result['success'] else None,
                            'success': extraction_result['success'] if extraction_result else False,
                            'extraction_metadata': extraction_result.get('metadata', {}) if extraction_result and extraction_result['success'] else {}
                        },
                        **(metadata_extra or {})
                    }
                }
                
                return [documento]
                
            except Exception as e:
                logger.error(f"‚ùå Erro no upload/processamento: {e}")
                return []
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar arquivo final {nome_original}: {e}")
            return []
    
    # ================================
    # UTILIT√ÅRIOS
    # ================================
    
    def _limpar_nome_arquivo(self, nome: str) -> str:
        """Remove caracteres problem√°ticos e acentos"""
        import re
        import unicodedata
        
        # üîß CORRE√á√ÉO: Remover acentos convertendo para ASCII
        nome_limpo = unicodedata.normalize('NFKD', nome)
        nome_limpo = ''.join(c for c in nome_limpo if not unicodedata.combining(c))
        
        # Remover espa√ßos e caracteres especiais, manter apenas letras, n√∫meros, h√≠fen, underscore e ponto
        nome_limpo = re.sub(r'[^\w\-_\.]', '_', nome_limpo)
        
        # Remover underscores m√∫ltiplos
        nome_limpo = re.sub(r'_+', '_', nome_limpo)
        
        # Remover underscores no in√≠cio e fim
        nome_limpo = nome_limpo.strip('_')
        
        return nome_limpo
    
    def _detectar_extensao(self, content: bytes, nome: str) -> str:
        """Detecta extens√£o correta do arquivo"""
        # Primeiro, verificar se j√° tem extens√£o v√°lida
        for ext in self.allowed_extensions:
            if nome.lower().endswith(ext):
                return ext
        
        # üîß CORRE√á√ÉO: Detectar pelo magic bytes do PDF
        if content.startswith(b'%PDF'):
            logger.info("üìÑ Arquivo detectado como PDF pelos magic bytes")
            return '.pdf'
        
        # üîß CORRE√á√ÉO: Detectar ZIP (magic bytes PK)
        if content.startswith(b'PK\x03\x04') or content.startswith(b'PK\x05\x06') or content.startswith(b'PK\x07\x08'):
            logger.info("üì¶ Arquivo detectado como ZIP pelos magic bytes")
            return '.zip'
        
        # Detectar pelo conte√∫do usando python-magic
        try:
            mime_type = magic.from_buffer(content[:2048], mime=True)
            logger.info(f"üîç MIME type detectado: {mime_type}")
            
            if 'pdf' in mime_type.lower():
                return '.pdf'
            elif 'word' in mime_type.lower() or 'document' in mime_type.lower():
                return '.docx'
            elif 'text' in mime_type.lower():
                return '.txt'
            elif 'zip' in mime_type.lower():
                return '.zip'
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao detectar MIME type: {e}")
        
        # üîß CORRE√á√ÉO: Verifica√ß√£o adicional para HTML (que indica erro)
        if content.startswith(b'<!DOCTYPE') or content.startswith(b'<html'):
            logger.error("‚ùå Conte√∫do detectado como HTML - poss√≠vel erro no download")
            return '.html'
        
        # Padr√£o (assumir PDF se n√£o conseguir detectar)
        logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel detectar extens√£o, assumindo PDF")
        return '.pdf'
    
    def _get_mime_type(self, extensao: str) -> str:
        """Retorna MIME type baseado na extens√£o"""
        mime_types = {
            '.pdf': 'application/pdf',
            '.doc': 'application/msword',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.txt': 'text/plain',
            '.rtf': 'application/rtf',
            '.odt': 'application/vnd.oasis.opendocument.text'
        }
        return mime_types.get(extensao, 'application/octet-stream')
    
    def _extrair_texto_pdf_fallback(self, pdf_content: bytes, max_chars: int = 1000) -> Optional[str]:
        """Extrai preview do texto de um PDF usando PyPDF2 (m√©todo fallback)"""
        try:
            logger.info(f"üîÑ Usando fallback PyPDF2 para extra√ß√£o")
            pdf_file = io.BytesIO(pdf_content)
            reader = PyPDF2.PdfReader(pdf_file)
            text = ""
            
            for i, page in enumerate(reader.pages[:3]):
                text += page.extract_text() + "\n"
                if len(text) > max_chars:
                    break
            
            preview = text[:max_chars].strip() if text.strip() else None
            if preview:
                logger.info(f"‚úÖ Fallback PyPDF2 extraiu {len(preview)} caracteres")
            return preview
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erro no fallback PyPDF2: {e}")
            return None
    
    # ================================
    # BANCO DE DADOS SIMPLIFICADO
    # ================================
    
    def salvar_documentos_no_banco(self, documentos: List[Dict]) -> Dict[str, Any]:
        """Salva todos os documentos na tabela unificada"""
        try:
            logger.info(f"üíæ Salvando {len(documentos)} documentos no banco")
            
            documentos_salvos = 0
            
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    for doc in documentos:
                        try:
                            documento_id = str(uuid.uuid4())
                            
                            cursor.execute("""
                                INSERT INTO documentos_licitacao (
                                    id, licitacao_id, titulo, arquivo_nuvem_url,
                                    tipo_arquivo, tamanho_arquivo, hash_arquivo,
                                    texto_preview, metadata_arquivo
                                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            """, (
                                documento_id,
                                doc['licitacao_id'],
                                doc['titulo'],
                                doc['arquivo_nuvem_url'],
                                doc['tipo_arquivo'],
                                doc['tamanho_arquivo'],
                                doc['hash_arquivo'],
                                doc.get('texto_preview'),
                                json.dumps(doc['metadata_arquivo'])
                            ))
                            
                            documentos_salvos += 1
                            logger.info(f"‚úÖ Documento salvo: {doc['titulo']}")
                            
                        except Exception as e:
                            logger.error(f"‚ùå Erro ao salvar documento {doc.get('titulo', 'sem t√≠tulo')}: {e}")
                            continue
                    
                    conn.commit()
            
            logger.info(f"‚úÖ {documentos_salvos} documentos salvos no banco")
            
            return {
                'success': True,
                'documentos_salvos': documentos_salvos,
                'total_documentos': len(documentos)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar documentos: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def obter_documentos_licitacao(self, licitacao_id: str) -> List[Dict]:
        """Obt√©m todos os documentos de uma licita√ß√£o"""
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    cursor.execute("""
                        SELECT * FROM documentos_licitacao 
                        WHERE licitacao_id = %s 
                        ORDER BY titulo
                    """, (licitacao_id,))
                    
                    documentos = cursor.fetchall()
                    return [dict(doc) for doc in documentos]
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter documentos: {e}")
            return []
    
    # ================================
    # M√âTODOS DE VALIDA√á√ÉO E TESTE
    # ================================

    def validar_configuracao(self) -> Dict[str, Any]:
        """Valida configura√ß√£o inicial do processador"""
        try:
            logger.info("üîß Validando configura√ß√£o do processador...")
            
            validacao = {
                'database': False,
                'supabase': False,
                'bucket': False,
                'temp_directory': False,
                'detalhes': {}
            }
            
            # 1. Testar conex√£o com banco
            try:
                with self.db_manager.get_connection() as conn:
                    with conn.cursor() as cursor:
                        cursor.execute("SELECT 1")
                        validacao['database'] = True
                        logger.info("‚úÖ Conex√£o com banco validada")
            except Exception as e:
                validacao['detalhes']['database_error'] = str(e)
                logger.error(f"‚ùå Erro conex√£o banco: {e}")
            
            # 2. Testar conex√£o Supabase (teste direto do bucket)
            try:
                # Ao inv√©s de listar buckets, testar acesso direto ao bucket
                files = self.storage_service.list("")  # Lista raiz do bucket
                validacao['supabase'] = True
                logger.info("‚úÖ Conex√£o Supabase validada")
            except Exception as e:
                validacao['detalhes']['supabase_error'] = str(e)
                logger.warning(f"‚ö†Ô∏è Aviso Supabase (normal com ANON_KEY): {e}")
                # Considerar v√°lido mesmo com erro de permiss√£o
                validacao['supabase'] = True
            
            # 3. Testar bucket
            try:
                files = self.storage_service.list()
                validacao['bucket'] = True
                logger.info(f"‚úÖ Bucket '{self.bucket_name}' acess√≠vel")
            except Exception as e:
                validacao['detalhes']['bucket_error'] = str(e)
                logger.error(f"‚ùå Erro bucket: {e}")
            
            # 4. Testar diret√≥rio tempor√°rio
            try:
                test_file = self.temp_path / "test_validation.txt"
                test_file.write_text("teste")
                test_file.unlink()
                validacao['temp_directory'] = True
                logger.info("‚úÖ Diret√≥rio tempor√°rio funcional")
            except Exception as e:
                validacao['detalhes']['temp_directory_error'] = str(e)
                logger.error(f"‚ùå Erro diret√≥rio temp: {e}")
            
            # Status geral
            validacao['status_geral'] = all([
                validacao['database'],
                validacao['supabase'], 
                validacao['bucket'],
                validacao['temp_directory']
            ])
            
            if validacao['status_geral']:
                logger.info("üéâ Todas as valida√ß√µes passaram!")
            else:
                logger.warning("‚ö†Ô∏è Algumas valida√ß√µes falharam")
            
            return validacao
            
        except Exception as e:
            logger.error(f"‚ùå Erro na valida√ß√£o: {e}")
            return {
                'status_geral': False,
                'error': str(e)
            }

    def listar_licitacoes_banco(self, limit: int = 10) -> List[Dict]:
        """Lista licita√ß√µes dispon√≠veis no banco para teste"""
        try:
            logger.info(f"üîç Buscando {limit} licita√ß√µes no banco...")
            
            with self.db_manager.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    cursor.execute("""
                        SELECT 
                            id, pncp_id, orgao_cnpj, ano_compra, sequencial_compra,
                            objeto_compra, modalidade_nome, valor_total_estimado,
                            uf, data_publicacao, status,
                            -- Verificar se j√° tem documentos processados
                            (SELECT COUNT(*) FROM documentos_licitacao WHERE licitacao_id = l.id) as docs_count
                        FROM licitacoes l
                        ORDER BY data_publicacao DESC 
                        LIMIT %s
                    """, (limit,))
                    
                    licitacoes = cursor.fetchall()
                    resultado = []
                    
                    for i, lic in enumerate(licitacoes, 1):
                        lic_dict = dict(lic)
                        lic_dict['numero_ordem'] = i
                        lic_dict['ja_processado'] = lic_dict['docs_count'] > 0
                        resultado.append(lic_dict)
                    
                    logger.info(f"‚úÖ Encontradas {len(resultado)} licita√ß√µes")
                    return resultado
                    
        except Exception as e:
            logger.error(f"‚ùå Erro ao listar licita√ß√µes: {e}")
            return []

    def exibir_licitacoes_formatadas(self, licitacoes: List[Dict]) -> None:
        """Exibe licita√ß√µes de forma formatada para escolha"""
        print("\n" + "="*80)
        print("üìã LICITA√á√ïES DISPON√çVEIS PARA TESTE")
        print("="*80)
        
        for lic in licitacoes:
            status_docs = "‚úÖ J√Å PROCESSADO" if lic['ja_processado'] else "‚è≥ N√ÉO PROCESSADO"
            print(f"\n{lic['numero_ordem']:2d}. ID: {lic['id']}")
            print(f"    PNCP ID: {lic['pncp_id']}")
            print(f"    Objeto: {lic['objeto_compra'][:80]}...")
            print(f"    Modalidade: {lic['modalidade_nome']} | UF: {lic['uf']}")
            print(f"    Valor: R$ {lic['valor_total_estimado']:,.2f}" if lic['valor_total_estimado'] else "    Valor: N√£o informado")
            print(f"    Data: {lic['data_publicacao']}")
            print(f"    Documentos: {status_docs} ({lic['docs_count']} docs)")
        
        print("\n" + "="*80)

    def teste_processamento_licitacao(self, licitacao_id: str, forcar_reprocessamento: bool = False) -> Dict[str, Any]:
        """Testa o processamento completo de uma licita√ß√£o"""
        try:
            print(f"\nüß™ TESTE DE PROCESSAMENTO")
            print(f"Licita√ß√£o ID: {licitacao_id}")
            print(f"For√ßar reprocessamento: {forcar_reprocessamento}")
            print("-" * 50)
            
            # 1. Validar configura√ß√£o primeiro
            print("1Ô∏è‚É£ Validando configura√ß√£o...")
            validacao = self.validar_configuracao()
            if not validacao['status_geral']:
                return {
                    'success': False,
                    'error': 'Configura√ß√£o inv√°lida',
                    'detalhes': validacao
                }
            print("‚úÖ Configura√ß√£o OK")
            
            # 2. Verificar se licita√ß√£o existe
            print("2Ô∏è‚É£ Verificando licita√ß√£o...")
            licitacao_info = self.extrair_info_licitacao(licitacao_id)
            if not licitacao_info:
                return {
                    'success': False,
                    'error': 'Licita√ß√£o n√£o encontrada'
                }
            print(f"‚úÖ Licita√ß√£o encontrada: {licitacao_info['objeto_compra'][:50]}...")
            
            # 3. Verificar documentos existentes
            print("3Ô∏è‚É£ Verificando documentos existentes...")
            docs_existem = self.verificar_documentos_existem(licitacao_id)
            
            if docs_existem and not forcar_reprocessamento:
                docs_existentes = self.obter_documentos_licitacao(licitacao_id)
                print(f"‚ö†Ô∏è {len(docs_existentes)} documentos j√° processados")
                print("üí° Use forcar_reprocessamento=True para reprocessar")
                return {
                    'success': True,
                    'message': 'Documentos j√° processados',
                    'documentos_existentes': len(docs_existentes),
                    'action_needed': 'Use forcar_reprocessamento=True para reprocessar'
                }
            
            # 4. Limpar documentos se for√ßando reprocessamento
            if docs_existem and forcar_reprocessamento:
                print("üóëÔ∏è Removendo documentos existentes...")
                self._limpar_documentos_licitacao(licitacao_id)
            
            # 5. Processar documentos
            print("4Ô∏è‚É£ Iniciando processamento...")
            resultado = self.processar_documentos_licitacao(licitacao_id)
            
            if resultado['success']:
                print(f"üéâ Processamento conclu√≠do!")
                print(f"üìÑ Documentos processados: {resultado.get('documentos_processados', 0)}")
                print(f"‚òÅÔ∏è Storage: {resultado.get('storage_provider', 'N/A')}")
                print(f"üìÅ Pasta: {resultado.get('pasta_nuvem', 'N/A')}")
            else:
                print(f"‚ùå Erro no processamento: {resultado.get('error')}")
            
            return resultado
            
        except Exception as e:
            logger.error(f"‚ùå Erro no teste: {e}")
            return {
                'success': False,
                'error': f'Erro no teste: {str(e)}'
            }

    def _limpar_documentos_licitacao(self, licitacao_id: str) -> None:
        """Remove documentos de uma licita√ß√£o (para reprocessamento)"""
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(
                        "DELETE FROM documentos_licitacao WHERE licitacao_id = %s",
                        (licitacao_id,)
                    )
                    deleted_count = cursor.rowcount
                    conn.commit()
                    logger.info(f"üóëÔ∏è {deleted_count} documentos removidos do banco")
                    
        except Exception as e:
            logger.error(f"‚ùå Erro ao limpar documentos: {e}")

    def testar_url_documento(self, url: str) -> Dict[str, Any]:
        """Testa download de uma URL espec√≠fica para debugging"""
        try:
            logger.info(f"üß™ Testando URL: {url}")
            
            # Headers espec√≠ficos
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/pdf, application/octet-stream, */*',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive'
            }
            
            # Fazer requisi√ß√£o
            response = requests.get(url, headers=headers, timeout=120, stream=True)
            response.raise_for_status()
            
            # Analisar resposta
            content_type = response.headers.get('content-type', '').lower()
            content_length = response.headers.get('content-length', '0')
            
            resultado = {
                'url': url,
                'status_code': response.status_code,
                'content_type': content_type,
                'content_length': content_length,
                'headers': dict(response.headers),
                'content_preview': None,
                'is_binary': False,
                'is_pdf': False,
                'is_html': False,
                'is_zip': False,
                'hex_preview': None,
                'first_bytes': None
            }
            
            # Analisar conte√∫do
            content = response.content
            
            if content:
                resultado['actual_size'] = len(content)
                
                # üîç DEBUG: Analisar primeiros bytes
                resultado['first_bytes'] = content[:50]  # Primeiros 50 bytes
                resultado['hex_preview'] = ' '.join(f'{b:02x}' for b in content[:20])  # Primeiros 20 bytes em hex
                
                # Verificar se √© PDF (m√∫ltiplas formas)
                # 1. Magic bytes padr√£o
                if content.startswith(b'%PDF'):
                    resultado['is_pdf'] = True
                    resultado['is_binary'] = True
                    resultado['content_preview'] = f"PDF detectado (magic bytes) - {len(content)} bytes"
                
                # 2. Buscar %PDF nos primeiros 1000 bytes (pode ter headers)
                elif b'%PDF' in content[:1000]:
                    pdf_start = content.find(b'%PDF')
                    resultado['is_pdf'] = True
                    resultado['is_binary'] = True
                    resultado['content_preview'] = f"PDF detectado (offset {pdf_start}) - {len(content)} bytes"
                
                # 3. Verificar se √© ZIP (magic bytes PK)
                elif content.startswith(b'PK\x03\x04') or content.startswith(b'PK\x05\x06') or content.startswith(b'PK\x07\x08'):
                    resultado['is_zip'] = True
                    resultado['is_binary'] = True
                    resultado['content_preview'] = f"ZIP detectado - {len(content)} bytes (provavelmente cont√©m PDF)"
                
                # 4. Verificar header bytes comuns de PDF
                elif any(content.startswith(header) for header in [b'\x00\x00\x00', b'\xff\xfe', b'\xfe\xff']):
                    # Pode ser PDF com BOM ou headers especiais
                    if b'PDF' in content[:2048]:
                        resultado['is_pdf'] = True
                        resultado['is_binary'] = True
                        resultado['content_preview'] = f"PDF detectado (com headers) - {len(content)} bytes"
                
                # Verificar se √© HTML
                elif content.startswith(b'<!DOCTYPE') or content.startswith(b'<html'):
                    resultado['is_html'] = True
                    resultado['content_preview'] = content[:500].decode('utf-8', errors='ignore')
                
                # Conte√∫do bin√°rio gen√©rico
                elif any(b in content[:100] for b in [b'\x00', b'\xff', b'\xfe']):
                    resultado['is_binary'] = True
                    resultado['content_preview'] = f"Arquivo bin√°rio detectado - {len(content)} bytes"
                
                # Texto/outros
                else:
                    try:
                        resultado['content_preview'] = content[:500].decode('utf-8', errors='ignore')
                    except:
                        resultado['content_preview'] = f"Conte√∫do n√£o-texto - {len(content)} bytes"
            
            logger.info(f"‚úÖ Teste conclu√≠do")
            return resultado
            
        except Exception as e:
            logger.error(f"‚ùå Erro no teste: {e}")
            return {
                'url': url,
                'error': str(e),
                'success': False
            }

    def executar_demo_interativo(self) -> None:
        """Executa demo interativo do processador"""
        try:
            print("\nüöÄ DEMO INTERATIVO - UNIFIED DOCUMENT PROCESSOR")
            print("="*60)
            
            # 1. Validar configura√ß√£o
            print("\n1Ô∏è‚É£ Validando configura√ß√£o...")
            validacao = self.validar_configuracao()
            
            if not validacao['status_geral']:
                print("‚ùå Configura√ß√£o inv√°lida! Verifique os erros:")
                for key, error in validacao.get('detalhes', {}).items():
                    print(f"   - {key}: {error}")
                return
            
            print("‚úÖ Configura√ß√£o validada com sucesso!")
            
            # 2. Listar licita√ß√µes
            print("\n2Ô∏è‚É£ Carregando licita√ß√µes dispon√≠veis...")
            licitacoes = self.listar_licitacoes_banco(10)
            
            if not licitacoes:
                print("‚ùå Nenhuma licita√ß√£o encontrada no banco")
                return
            
            self.exibir_licitacoes_formatadas(licitacoes)
            
            # 3. Escolher licita√ß√£o
            while True:
                try:
                    escolha = input("\nüî¢ Digite o n√∫mero da licita√ß√£o para testar (ou 'q' para sair): ").strip()
                    
                    if escolha.lower() == 'q':
                        print("üëã Saindo...")
                        return
                    
                    num = int(escolha)
                    if 1 <= num <= len(licitacoes):
                        licitacao_escolhida = licitacoes[num - 1]
                        break
                    else:
                        print(f"‚ùå N√∫mero inv√°lido. Digite entre 1 e {len(licitacoes)}")
                        
                except ValueError:
                    print("‚ùå Digite um n√∫mero v√°lido ou 'q' para sair")
            
            # 4. Confirmar processamento
            print(f"\nüìã Licita√ß√£o selecionada:")
            print(f"   ID: {licitacao_escolhida['id']}")
            print(f"   Objeto: {licitacao_escolhida['objeto_compra'][:100]}...")
            print(f"   Status documentos: {'J√Å PROCESSADO' if licitacao_escolhida['ja_processado'] else 'N√ÉO PROCESSADO'}")
            
            forcar = False
            if licitacao_escolhida['ja_processado']:
                resposta = input("\n‚ö†Ô∏è Documentos j√° processados. Reprocessar? (s/N): ").strip().lower()
                forcar = resposta in ['s', 'sim', 'y', 'yes']
            
            # 5. Executar teste
            print(f"\nüß™ Executando teste de processamento...")
            resultado = self.teste_processamento_licitacao(
                licitacao_escolhida['id'], 
                forcar_reprocessamento=forcar
            )
            
            # 6. Mostrar resultados finais
            print(f"\nüìä RESULTADO FINAL:")
            print(f"‚úÖ Sucesso: {resultado['success']}")
            
            if resultado['success']:
                print(f"üìÑ Documentos: {resultado.get('documentos_processados', 'N/A')}")
                print(f"üí¨ Mensagem: {resultado.get('message', 'N/A')}")
            else:
                print(f"‚ùå Erro: {resultado.get('error', 'N/A')}")
            
            print("\nüéâ Demo conclu√≠do!")
            
        except KeyboardInterrupt:
            print("\n\n‚èπÔ∏è Demo interrompido pelo usu√°rio")
        except Exception as e:
            print(f"\n‚ùå Erro no demo: {e}")
            logger.error(f"Erro no demo interativo: {e}")

    # ================================
    # FUN√á√ÉO PRINCIPAL
    # ================================
    
    async def processar_documentos_licitacao(self, licitacao_id: str) -> Dict[str, Any]:
        """Fun√ß√£o principal unificada"""
        try:
            logger.info(f"üöÄ INICIANDO processamento unificado: {licitacao_id}")
            
            # PASSO 1: Extrair informa√ß√µes
            licitacao_info = self.extrair_info_licitacao(licitacao_id)
            if not licitacao_info:
                return {'success': False, 'error': 'Licita√ß√£o n√£o encontrada'}
            
            # PASSO 2: Verificar se j√° existe
            if self.verificar_documentos_existem(licitacao_id):
                return {
                    'success': True,
                    'message': 'Documentos j√° processados',
                    'documentos_processados': 0
                }
            
            # PASSO 3: Garantir que bucket existe
            bucket_exists = await self.storage_service.ensure_bucket_exists()
            if not bucket_exists:
                return {
                    'success': False,
                    'error': 'Erro ao criar/verificar bucket de armazenamento'
                }
            
            # PASSO 4: Construir URL da API
            logger.info("üîß PASSO 3: Construindo URL da API")
            api_url = self._construir_url_api(licitacao_info)
            logger.info("‚úÖ PASSO 3 OK: URL constru√≠da")
            
            # PASSO 5: Processar resposta flex√≠vel
            documentos = self.processar_resposta_pncp(api_url, licitacao_id)
            
            if not documentos:
                logger.warning("‚ö†Ô∏è N√£o foi poss√≠vel processar documentos")
                return {
                    'success': False,
                    'error': 'Falha ao processar documentos da API PNCP'
                }
            
            # PASSO 6: Salvar no banco
            resultado = self.salvar_documentos_no_banco(documentos)
            
            if resultado['success']:
                logger.info(f"üéâ Processamento conclu√≠do com sucesso!")
                return {
                    'success': True,
                    'message': 'Processamento conclu√≠do',
                    'licitacao_id': licitacao_id,
                    'documentos_processados': resultado['documentos_salvos'],
                    'storage_provider': 'supabase',
                    'pasta_nuvem': f"licitacoes/{licitacao_id}/"
                }
            else:
                return resultado
                
        except Exception as e:
            logger.error(f"‚ùå ERRO no processamento: {e}")
            return {
                'success': False,
                'error': f'Erro no processamento: {str(e)}'
            }

    def corrigir_urls_documentos(self, licitacao_id: str = None) -> Dict[str, Any]:
        """
        üîß NOVA FUN√á√ÉO: Corrige URLs de documentos que est√£o com problemas (terminando com ?)
        """
        try:
            logger.info("üîß Iniciando corre√ß√£o de URLs de documentos...")
            
            with self.db_manager.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    # Query para buscar documentos com URLs problem√°ticas
                    if licitacao_id:
                        query = """
                            SELECT id, licitacao_id, titulo, arquivo_nuvem_url, metadata_arquivo 
                            FROM documentos_licitacao 
                            WHERE licitacao_id = %s AND arquivo_nuvem_url LIKE '%?'
                        """
                        cursor.execute(query, (licitacao_id,))
                    else:
                        query = """
                            SELECT id, licitacao_id, titulo, arquivo_nuvem_url, metadata_arquivo 
                            FROM documentos_licitacao 
                            WHERE arquivo_nuvem_url LIKE '%?'
                        """
                        cursor.execute(query)
                    
                    documentos_problematicos = cursor.fetchall()
                    
                    if not documentos_problematicos:
                        logger.info("‚úÖ Nenhum documento com URL problem√°tica encontrado")
                        return {'success': True, 'documentos_corrigidos': 0, 'message': 'Nenhuma corre√ß√£o necess√°ria'}
                    
                    logger.info(f"üîç Encontrados {len(documentos_problematicos)} documentos com URLs problem√°ticas")
                    
                    documentos_corrigidos = 0
                    
                    for doc in documentos_problematicos:
                        try:
                            # Extrair cloud_path do metadata
                            metadata = json.loads(doc['metadata_arquivo']) if doc['metadata_arquivo'] else {}
                            cloud_path = metadata.get('cloud_path')
                            
                            if cloud_path:
                                # Gerar nova URL limpa
                                raw_url = self.storage_service.get_public_url(cloud_path)
                                
                                # Limpar URL
                                if raw_url.endswith('?'):
                                    nova_url = raw_url[:-1]
                                elif '?' in raw_url and not any(param for param in raw_url.split('?')[1].split('&') if '=' in param):
                                    nova_url = raw_url.split('?')[0]
                                else:
                                    nova_url = raw_url
                                
                                # Atualizar no banco
                                cursor.execute("""
                                    UPDATE documentos_licitacao 
                                    SET arquivo_nuvem_url = %s, updated_at = NOW()
                                    WHERE id = %s
                                """, (nova_url, doc['id']))
                                
                                logger.info(f"‚úÖ URL corrigida para: {doc['titulo']}")
                                documentos_corrigidos += 1
                            else:
                                logger.warning(f"‚ö†Ô∏è N√£o h√° cloud_path para: {doc['titulo']}")
                        
                        except Exception as e:
                            logger.error(f"‚ùå Erro ao corrigir documento {doc['titulo']}: {e}")
                            continue
                    
                    conn.commit()
                    
                    logger.info(f"üéâ Corre√ß√£o conclu√≠da: {documentos_corrigidos} URLs corrigidas")
                    
                    return {
                        'success': True,
                        'documentos_corrigidos': documentos_corrigidos,
                        'total_problematicos': len(documentos_problematicos)
                    }
        
        except Exception as e:
            logger.error(f"‚ùå Erro na corre√ß√£o de URLs: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def sincronizar_documentos_storage(self, licitacao_id: str) -> Dict[str, Any]:
        """
        üîÑ NOVA FUN√á√ÉO: Sincroniza documentos entre storage e banco
        Garante que todos os arquivos no storage estejam no banco
        """
        try:
            logger.info(f"üîÑ Sincronizando documentos storage ‚Üî banco para: {licitacao_id}")
            
            # 1. Listar arquivos no storage
            files_storage = self.storage_service.list(f"licitacoes/{licitacao_id}")
            logger.info(f"üìÅ {len(files_storage)} arquivos encontrados no storage")
            
            # 2. Listar documentos no banco
            documentos_banco = self.obter_documentos_licitacao(licitacao_id)
            logger.info(f"üíæ {len(documentos_banco)} documentos encontrados no banco")
            
            # 3. Identificar arquivos que est√£o no storage mas n√£o no banco
            nomes_banco = set()
            for doc in documentos_banco:
                metadata = doc.get('metadata_arquivo', {})
                if isinstance(metadata, str):
                    metadata = json.loads(metadata)
                cloud_path = metadata.get('cloud_path', '')
                if cloud_path:
                    nome_arquivo = cloud_path.split('/')[-1]
                    nomes_banco.add(nome_arquivo)
            
            nomes_storage = {file['name'] for file in files_storage}
            arquivos_faltando = nomes_storage - nomes_banco
            
            if not arquivos_faltando:
                logger.info("‚úÖ Todos os arquivos do storage j√° est√£o no banco")
                return {
                    'success': True,
                    'arquivos_adicionados': 0,
                    'message': 'Sincroniza√ß√£o j√° est√° em dia'
                }
            
            logger.info(f"üìã {len(arquivos_faltando)} arquivos precisam ser adicionados ao banco")
            
            # 4. Adicionar arquivos faltando ao banco
            documentos_novos = []
            
            for nome_arquivo in arquivos_faltando:
                try:
                    # Gerar informa√ß√µes do documento
                    cloud_path = f"licitacoes/{licitacao_id}/{nome_arquivo}"
                    
                    # Extrair sequencial e nome original do nome do arquivo
                    if '_' in nome_arquivo:
                        parts = nome_arquivo.split('_', 1)
                        sequencial = int(parts[0]) if parts[0].isdigit() else 1
                        nome_original = parts[1]
                    else:
                        sequencial = 1
                        nome_original = nome_arquivo
                    
                    # Determinar extens√£o e tipo
                    extensao = os.path.splitext(nome_arquivo)[1].lower()
                    tipo_arquivo = self._get_mime_type(extensao)
                    
                    # Obter informa√ß√µes do arquivo no storage
                    file_info = next((f for f in files_storage if f['name'] == nome_arquivo), None)
                    tamanho_arquivo = file_info.get('metadata', {}).get('size', 0) if file_info else 0
                    
                    # Gerar URL limpa
                    raw_url = self.storage_service.get_public_url(cloud_path)
                    if raw_url.endswith('?'):
                        arquivo_url = raw_url[:-1]
                    else:
                        arquivo_url = raw_url
                    
                    # Criar documento
                    documento = {
                        'licitacao_id': licitacao_id,
                        'titulo': nome_original,
                        'arquivo_nuvem_url': arquivo_url,
                        'tipo_arquivo': tipo_arquivo,
                        'tamanho_arquivo': tamanho_arquivo,
                        'hash_arquivo': f"sync_{uuid.uuid4().hex[:16]}",  # Hash tempor√°rio
                        'texto_preview': None,
                        'metadata_arquivo': {
                            'nome_original': nome_original,
                            'nome_limpo': nome_arquivo,
                            'extensao': extensao,
                            'sequencial': sequencial,
                            'cloud_path': cloud_path,
                            'storage_provider': 'supabase',
                            'bucket_name': self.bucket_name,
                            'sincronizado_em': datetime.now().isoformat(),
                            'origem': 'sincronizacao_storage'
                        }
                    }
                    
                    documentos_novos.append(documento)
                    logger.info(f"üìÑ Preparado para adicionar: {nome_arquivo}")
                
                except Exception as e:
                    logger.error(f"‚ùå Erro ao preparar documento {nome_arquivo}: {e}")
                    continue
            
            # 5. Salvar documentos novos no banco
            if documentos_novos:
                resultado_save = self.salvar_documentos_no_banco(documentos_novos)
                
                return {
                    'success': True,
                    'arquivos_storage': len(files_storage),
                    'documentos_banco_antes': len(documentos_banco),
                    'arquivos_adicionados': resultado_save.get('documentos_salvos', 0),
                    'arquivos_faltando_antes': len(arquivos_faltando)
                }
            else:
                return {
                    'success': False,
                    'error': 'Nenhum documento novo foi preparado com sucesso'
                }
        
        except Exception as e:
            logger.error(f"‚ùå Erro na sincroniza√ß√£o: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def _construir_url_api(self, licitacao: Dict[str, Any]) -> str:
        """Constr√≥i URL da API PNCP"""
        cnpj = licitacao['orgao_cnpj']
        ano = licitacao['ano_compra']
        sequencial = licitacao['sequencial_compra']
        
        return f"https://pncp.gov.br/pncp-api/v1/orgaos/{cnpj}/compras/{ano}/{sequencial}/arquivos"
    
    def testar_extrator_texto(self, licitacao_id: str = None) -> Dict[str, Any]:
        """
        üß™ Testar funcionalidade do extrator de texto avan√ßado
        """
        try:
            logger.info("üß™ Iniciando teste do extrator de texto avan√ßado")
            
            resultado = {
                'success': True,
                'extrator_status': self.text_extractor.get_extractor_status(),
                'testes': [],
                'resumo': {}
            }
            
            # Teste 1: Status dos extractors
            status_extractors = self.text_extractor.get_extractor_status()
            resultado['testes'].append({
                'teste': 'status_extractors',
                'resultado': status_extractors,
                'aprovado': len(status_extractors['available_extractors']) > 0
            })
            
            # Teste 2: Se licitacao_id fornecido, testar extra√ß√£o real
            if licitacao_id:
                documentos = self.obter_documentos_licitacao(licitacao_id)
                if documentos:
                    for doc in documentos[:1]:  # Testar apenas o primeiro
                        try:
                            # Download do arquivo para teste
                            response = requests.get(doc['arquivo_nuvem_url'], timeout=30)
                            if response.status_code == 200:
                                # Testar extra√ß√£o
                                resultado_extracao = self.text_extractor.extract_text_unified(
                                    response.content, 
                                    doc['titulo']
                                )
                                
                                resultado['testes'].append({
                                    'teste': f'extracao_{doc["titulo"]}',
                                    'resultado': resultado_extracao,
                                    'aprovado': resultado_extracao['success']
                                })
                                break
                        except Exception as e:
                            resultado['testes'].append({
                                'teste': f'erro_extracao_{doc.get("titulo", "unknown")}',
                                'resultado': str(e),
                                'aprovado': False
                            })
            
            # Resumo
            testes_aprovados = sum(1 for t in resultado['testes'] if t['aprovado'])
            resultado['resumo'] = {
                'total_testes': len(resultado['testes']),
                'testes_aprovados': testes_aprovados,
                'taxa_sucesso': testes_aprovados / len(resultado['testes']) * 100 if resultado['testes'] else 0
            }
            
            return resultado
            
        except Exception as e:
            logger.error(f"‚ùå Erro no teste do extrator: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    # üÜï NOVO M√âTODO S√çNCRONO para resolver problema async/await
    def processar_licitacao_sync(self, licitacao_id: str, pncp_id: str, bid: Dict) -> Dict[str, Any]:
        """
        Vers√£o s√≠ncrona do processamento de documentos de licita√ß√£o
        
        Args:
            licitacao_id: ID da licita√ß√£o
            pncp_id: ID PNCP da licita√ß√£o  
            bid: Dados da licita√ß√£o do banco
            
        Returns:
            Dict com resultado do processamento
        """
        try:
            logger.info(f"üöÄ SYNC: Processando licitacao_id: {licitacao_id}, pncp_id: {pncp_id}")
            
            # PASSO 1: Verificar se documentos j√° existem
            if self.verificar_documentos_existem(licitacao_id):
                logger.info("‚úÖ SYNC: Documentos j√° processados")
                return {
                    'success': True,
                    'status': 'already_processed',
                    'message': 'Documentos j√° foram processados anteriormente',
                    'documentos_encontrados': len(self.obter_documentos_licitacao(licitacao_id))
                }
            
            # PASSO 2: Construir URL da API PNCP
            url_documentos = self.construir_url_documentos(bid)
            logger.info(f"üîó SYNC: URL documentos: {url_documentos}")
            
            # PASSO 3: Buscar e processar documentos da API
            # CORRE√á√ÉO: Chamando o m√©todo correto que processa a resposta da API
            documentos_processados = self.processar_resposta_pncp(url_documentos, licitacao_id)
            
            if not documentos_processados:
                logger.warning(f"Nenhum documento encontrado ou processado da API PNCP para {pncp_id}")
                return {
                    'success': True,
                    'status': 'no_documents_found',
                    'message': 'Nenhum documento encontrado na API PNCP, mas o processo n√£o falhou.'
                }
            
            logger.info(f"üìÑ SYNC: {len(documentos_processados)} documentos encontrados e processados da API")

            # PASSO 4: Salvar no banco de dados
            resultado_banco = self.salvar_documentos_no_banco(documentos_processados)
            
            if resultado_banco['success']:
                logger.info(f"üéâ SYNC: Processamento conclu√≠do! {resultado_banco['documentos_salvos']} documentos salvos")
                
                return {
                    'success': True,
                    'status': 'completed',
                    'message': f'{resultado_banco["documentos_salvos"]} documentos processados com sucesso',
                    'documentos_processados': resultado_banco['documentos_salvos'],
                    'total_encontrados': len(documentos_processados)
                }
            else:
                return {
                    'success': False,
                    'error': f'Erro ao salvar no banco: {resultado_banco.get("error")}'
                }

        except Exception as e:
            logger.error(f"‚ùå SYNC: Erro geral no processamento: {e}", exc_info=True)
            return {
                'success': False,
                'error': f'Erro no processamento s√≠ncrono: {str(e)}'
            }
    
    # ===== NOVOS M√âTODOS PARA PREPARA√á√ÉO AUTOM√ÅTICA =====
    
    def set_licitacao_context(self, licitacao_id: str, pncp_id: str):
        """
        Configurar contexto da licita√ß√£o para processamento
        """
        self.current_licitacao_id = licitacao_id
        self.current_pncp_id = pncp_id
        logger.info(f"üéØ Contexto configurado: licitacao_id={licitacao_id}, pncp_id={pncp_id}")
    
    def process_licitacao_documents(self, pncp_id: str, licitacao_id: str) -> Dict[str, Any]:
        """
        Processar documentos de uma licita√ß√£o espec√≠fica (m√©todo principal)
        """
        try:
            logger.info(f"üöÄ Iniciando processamento de documentos para {pncp_id}")
            
            # PASSO 1: Verificar se documentos j√° existem
            if self.verificar_documentos_existem(licitacao_id):
                logger.info("‚úÖ Documentos j√° processados, retornando status")
                return {
                    'status': 'already_processed',
                    'documents_count': len(self.obter_documentos_licitacao(licitacao_id)),
                    'estimated_time': 0
                }
            
            # PASSO 2: Buscar informa√ß√µes da licita√ß√£o
            licitacao_info = self.extrair_info_licitacao(licitacao_id)
            if not licitacao_info:
                raise ValueError(f"Licita√ß√£o {licitacao_id} n√£o encontrada")
            
            # PASSO 3: Construir URL da API PNCP
            url_documentos = self.construir_url_documentos(licitacao_info)
            
            # PASSO 4: Processar documentos da API
            documentos_processados = self.processar_resposta_pncp(url_documentos, licitacao_id)
            
            if not documentos_processados:
                logger.warning("‚ö†Ô∏è Nenhum documento processado")
                return {
                    'status': 'no_documents',
                    'documents_count': 0,
                    'estimated_time': 0
                }
            
            # PASSO 5: Salvar no banco
            resultado_salvamento = self.salvar_documentos_no_banco(documentos_processados)
            
            logger.info(f"‚úÖ Processamento conclu√≠do: {len(documentos_processados)} documentos")
            
            return {
                'status': 'completed',
                'documents_count': len(documentos_processados),
                'estimated_time': 0,
                'processed_files': [doc.get('nome_arquivo') for doc in documentos_processados],
                'database_result': resultado_salvamento
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro no processamento: {str(e)}")
            return {
                'status': 'error',
                'error': str(e),
                'documents_count': 0
            }
    
    def check_documents_status(self, licitacao_id: str) -> Dict[str, Any]:
        """
        Verificar status dos documentos processados
        """
        try:
            logger.info(f"üìä Verificando status dos documentos para {licitacao_id}")
            
            documentos = self.obter_documentos_licitacao(licitacao_id)
            
            if documentos:
                # Formatar lista de documentos para o frontend
                documents_list = []
                for doc in documentos:
                    documents_list.append({
                        'name': doc.get('nome_arquivo'),
                        'url': doc.get('url_publica'),
                        'type': doc.get('tipo_arquivo', 'pdf'),
                        'size': doc.get('tamanho_arquivo'),
                        'created_at': doc.get('data_criacao'),
                        'updated_at': doc.get('data_atualizacao')
                    })
                
                return {
                    'documents_processed': len(documentos),
                    'documents_list': documents_list,
                    'last_update': max([doc.get('data_atualizacao', '') for doc in documentos]) if documentos else None
                }
            else:
                return {
                    'documents_processed': 0,
                    'documents_list': [],
                    'last_update': None
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao verificar status: {str(e)}")
            return {
                'documents_processed': 0,
                'documents_list': [],
                'error': str(e)
            }
    
    def get_processing_status(self, licitacao_id: str) -> Dict[str, Any]:
        """
        Obter status de processamento em andamento (simulado por enquanto)
        """
        try:
            # Por enquanto, simular que n√£o h√° processamento em andamento
            # Em uma implementa√ß√£o real, isso consultaria uma tabela de jobs/tasks
            return {
                'is_processing': False,
                'current_step': 'waiting',
                'progress': 0,
                'eta': 0
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter status de processamento: {str(e)}")
            return {
                'is_processing': False,
                'error': str(e)
            }
    
    def get_current_timestamp(self) -> str:
        """
        Obter timestamp atual formatado
        """
        return datetime.now().isoformat()
    
    def cleanup_failed_processing(self, licitacao_id: str) -> Dict[str, Any]:
        """
        Limpar processamento que falhou
        """
        try:
            logger.info(f"üßπ Limpando processamento falhado para {licitacao_id}")
            
            # Remover documentos incompletos do banco
            self._limpar_documentos_licitacao(licitacao_id)
            
            # Remover arquivos tempor√°rios se existirem
            files_removed = 0
            temp_pattern = self.temp_path / f"*{licitacao_id}*"
            
            for temp_file in self.temp_path.glob(f"*{licitacao_id}*"):
                if temp_file.is_file():
                    temp_file.unlink()
                    files_removed += 1
            
            logger.info(f"‚úÖ Limpeza conclu√≠da: {files_removed} arquivos removidos")
            
            return {
                'files_removed': files_removed,
                'cleanup_status': 'success'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro na limpeza: {str(e)}")
            return {
                'files_removed': 0,
                'cleanup_status': 'error',
                'error': str(e)
            } 