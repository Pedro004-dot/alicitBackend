"""
ü¶ô VALIDADOR LLM LOCAL USANDO OLLAMA
Integra√ß√£o com qwen2.5:7b para valida√ß√£o de matches de licita√ß√µes
"""

import os
import json
import logging
import requests
import time
from typing import Dict, Any, Optional
from config.llm_config import LLMConfig
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv('config.env')

logger = logging.getLogger(__name__)

class OllamaMatchValidator:
    """
    ü¶ô Validador de matches usando Ollama local
    
    Usa qwen2.5:7b para an√°lise sem√¢ntica de compatibilidade
    entre empresas e licita√ß√µes, com fallback para OpenAI.
    """

    def __init__(self):
        """Inicializar o validador Ollama"""
        self.config = LLMConfig.get_ollama_config()
        self._setup_ollama()
        
        # Thresholds para valida√ß√£o (ajustados conforme config.env)
        self.HIGH_SCORE_THRESHOLD = float(os.getenv('SIMILARITY_THRESHOLD_PHASE1', '0.70'))  # Threshold do config.env
        self.LLM_CONFIDENCE_THRESHOLD = 0.65  # Aprova√ß√£o LLM
        
    def _setup_ollama(self):
        """Configurar conex√£o com Ollama"""
        try:
            response = requests.get(
                f"{self.config['url']}/api/tags",
                timeout=5
            )
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [m['name'] for m in models]
                
                if self.config['model'] in model_names:
                    logger.info(f"ü¶ô Ollama conectado - Modelo: {self.config['model']}")
                    self.ollama_available = True
                else:
                    logger.error(f"‚ùå Modelo {self.config['model']} n√£o encontrado. Dispon√≠veis: {model_names}")
                    self.ollama_available = False
            else:
                logger.error(f"‚ùå Ollama retornou status {response.status_code}")
                self.ollama_available = False
                
        except Exception as e:
            logger.error(f"‚ùå Erro conectando Ollama: {e}")
            self.ollama_available = False

    def should_validate_with_llm(self, score: float) -> bool:
        """
        üî• NOVA POL√çTICA: Validar TODOS os matches acima do threshold
        """
        return score >= self.HIGH_SCORE_THRESHOLD

    def validate_match(
        self,
        empresa_nome: str,
        empresa_descricao: str,
        licitacao_objeto: str,
        pncp_id: str,
        similarity_score: float,
        licitacao_itens: Optional[list] = None,
        empresa_produtos: Optional[list] = None  # üîÄ NOVO: Produtos da empresa
    ) -> Dict[str, Any]:
        """
        ü¶ô Validar match usando Ollama com fallback OpenAI
        
        Returns:
            Dict com 'is_valid', 'confidence', 'reasoning'
        """
        
        if not self.ollama_available:
            logger.warning("ü¶ô Ollama indispon√≠vel, usando fallback OpenAI")
            return self._fallback_to_openai(
                empresa_nome, empresa_descricao, licitacao_objeto, 
                pncp_id, similarity_score, licitacao_itens, empresa_produtos
            )
        
        try:
            start_time = time.time()
            
            # Construir prompt otimizado para qwen2.5:7b
            prompt = self._build_validation_prompt(
                empresa_nome, empresa_descricao, licitacao_objeto, similarity_score, licitacao_itens, empresa_produtos
            )
            
            # Fazer requisi√ß√£o para Ollama
            payload = {
                "model": self.config['model'],
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": self.config['temperature'],
                    "top_p": 0.9,
                    "repeat_penalty": 1.1
                }
            }
            
            response = requests.post(
                f"{self.config['url']}/api/generate",
                json=payload,
                timeout=self.config['timeout']
            )
            
            if response.status_code != 200:
                logger.error(f"‚ùå Ollama erro HTTP {response.status_code}")
                return self._fallback_to_openai(
                    empresa_nome, empresa_descricao, licitacao_objeto, 
                    pncp_id, similarity_score, licitacao_itens, empresa_produtos
                )
            
            result = response.json()
            llm_response = result.get('response', '').strip()
            
            processing_time = time.time() - start_time
            logger.info(f"ü¶ô Ollama processou em {processing_time:.2f}s")
            
            # Analisar resposta do LLM
            validation_result = self._parse_llm_response(llm_response, similarity_score)
            
            # Log detalhado
            logger.info(
                f"ü¶ô OLLAMA VALIDATION - "
                f"Empresa: {empresa_nome[:30]}... | "
                f"Objeto: {licitacao_objeto[:40]}... | "
                f"Score: {similarity_score:.1%} | "
                f"Decis√£o: {'‚úÖ APROVADO' if validation_result['is_valid'] else 'üö´ REJEITADO'} | "
                f"Confian√ßa: {validation_result['confidence']:.1%}"
            )
            
            return validation_result
            
        except Exception as e:
            logger.error(f"‚ùå Erro na valida√ß√£o Ollama: {e}")
            return self._fallback_to_openai(
                empresa_nome, empresa_descricao, licitacao_objeto, 
                pncp_id, similarity_score, licitacao_itens, empresa_produtos
            )

    def _build_validation_prompt(
        self, 
        empresa_nome: str, 
        empresa_descricao: str, 
        licitacao_objeto: str, 
        similarity_score: float,
        licitacao_itens: Optional[list] = None,
        empresa_produtos: Optional[list] = None
    ) -> str:
        """
        üöÄ Construir prompt OTIMIZADO espec√≠fico para cada modelo
        """
        
        # üîÄ Valida√ß√£o robusta dos par√¢metros de entrada
        if licitacao_itens is None:
            licitacao_itens = []
        elif isinstance(licitacao_itens, str):
            try:
                import json
                licitacao_itens = json.loads(licitacao_itens)
            except (json.JSONDecodeError, TypeError):
                licitacao_itens = []
        elif not isinstance(licitacao_itens, list):
            licitacao_itens = []
        
        if empresa_produtos is None:
            empresa_produtos = []
        elif isinstance(empresa_produtos, str):
            try:
                import json
                empresa_produtos = json.loads(empresa_produtos)
            except (json.JSONDecodeError, TypeError):
                empresa_produtos = []
        elif not isinstance(empresa_produtos, list):
            empresa_produtos = []
        
        # Formata√ß√£o otimizada dos dados
        produtos_texto = "\n".join([f"‚Ä¢ {p}" for p in empresa_produtos[:5]]) if empresa_produtos else "N√£o especificados"
        itens_texto = "\n".join([f"‚Ä¢ {item.get('descricao', str(item))[:80]}..." if isinstance(item, dict) 
                                else f"‚Ä¢ {str(item)[:80]}..." for item in licitacao_itens[:4]]) if licitacao_itens else "N√£o especificados"
        
        # üöÄ PROMPT OTIMIZADO PARA QWEN2.5:7B - Mais direto e estruturado
        if self.config['model'] in ['qwen2.5:7b', 'qwen2.5']:
            return f"""AN√ÅLISE R√ÅPIDA DE COMPATIBILIDADE COMERCIAL

EMPRESA: {empresa_nome}
PRODUTOS: {produtos_texto}

LICITA√á√ÉO: {licitacao_objeto[:150]}
ITENS: {itens_texto}

SCORE SEM√ÇNTICO: {similarity_score:.0%}

CRIT√âRIOS:
1. Produtos da empresa atendem itens da licita√ß√£o?
2. √Årea de atua√ß√£o √© compat√≠vel?
3. Empresa tem capacidade t√©cnica?

DECIS√ÉO: [SIM/N√ÉO]
CONFIAN√áA: [0-100]%
JUSTIFICATIVA: [m√°ximo 100 caracteres]"""

        # ü¶ô PROMPT MELHORADO PARA LLAMA3.2 - Mais reflexivo e criterioso
        else:
            return f"""VALIDA√á√ÉO CRITERIOSA DE COMPATIBILIDADE

### AN√ÅLISE DETALHADA NECESS√ÅRIA ###

EMPRESA CANDIDATA:
- Nome: {empresa_nome}
- Descri√ß√£o: {empresa_descricao[:100]}
- Produtos/Servi√ßos: {produtos_texto}

DEMANDA DA LICITA√á√ÉO:
- Objeto: {licitacao_objeto[:200]}
- Itens Espec√≠ficos: {itens_texto}
- Score Inicial: {similarity_score:.1%}

### INSTRU√á√ïES PARA AN√ÅLISE RIGOROSA ###

1. **PRIMEIRO PASSO**: Analise se os produtos da empresa s√£o DIRETAMENTE relacionados aos itens da licita√ß√£o
2. **SEGUNDO PASSO**: Verifique se a empresa tem EXPERI√äNCIA COMPROVADA na √°rea
3. **TERCEIRO PASSO**: Considere se √© COMERCIALMENTE VI√ÅVEL para a empresa participar
4. **DECIS√ÉO FINAL**: Seja CRITERIOSO - aprove apenas matches com alta probabilidade de sucesso

IMPORTANTE: 
- N√ÉO aprove por "poss√≠vel compatibilidade" - exija compatibilidade CLARA
- N√ÉO confunda √°rea geral com especializa√ß√£o espec√≠fica
- REJEITE se houver d√∫vidas significativas sobre capacidade

RESPOSTA OBRIGAT√ìRIA:
DECIS√ÉO: [SIM/N√ÉO]
CONFIAN√áA: [0-100]%
JUSTIFICATIVA: [explica√ß√£o da decis√£o em at√© 150 caracteres]"""

    def _parse_llm_response(self, response: str, similarity_score: float) -> Dict[str, Any]:
        """
        üß† Analisar resposta do LLM e extrair decis√£o estruturada
        """
        response_lower = response.lower().strip()
        
        # Buscar decis√£o
        is_valid = False
        confidence = 0.5  # Default
        reasoning = response.strip()
        
        # An√°lise de padr√µes na resposta
        if any(palavra in response_lower for palavra in ['sim', 'compat√≠vel', 'adequado', 'capaz']):
            is_valid = True
            confidence = 0.75
        elif any(palavra in response_lower for palavra in ['n√£o', 'incompat√≠vel', 'inadequado', 'incapaz']):
            is_valid = False
            confidence = 0.8
        
        # Buscar confian√ßa expl√≠cita (formato CONFIAN√áA: XX%)
        import re
        confidence_match = re.search(r'confian√ßa[:\s]*(\d+)%?', response_lower)
        if confidence_match:
            try:
                confidence = float(confidence_match.group(1)) / 100
            except:
                pass
        
        # Ajustar baseado no score sem√¢ntico
        if similarity_score >= 0.85:
            confidence = min(confidence + 0.1, 1.0)
        elif similarity_score <= 0.60:
            confidence = max(confidence - 0.1, 0.1)
        
        # Aplicar threshold de confian√ßa
        final_is_valid = is_valid and confidence >= self.LLM_CONFIDENCE_THRESHOLD
        
        return {
            'is_valid': final_is_valid,
            'confidence': confidence,
            'reasoning': reasoning[:200],  # Limitar tamanho
            'provider': 'ollama',
            'model': self.config['model']
        }

    def _fallback_to_openai(
        self,
        empresa_nome: str,
        empresa_descricao: str,
        licitacao_objeto: str,
        pncp_id: str,
        similarity_score: float,
        licitacao_itens: Optional[list] = None,
        empresa_produtos: Optional[list] = None  # üîÄ NOVO: Produtos da empresa
    ) -> Dict[str, Any]:
        """
        üîÑ Fallback para OpenAI quando Ollama falha
        """
        try:
            from matching.llm_match_validator import LLMMatchValidator
            
            logger.info("üîÑ Usando OpenAI como fallback...")
            openai_validator = LLMMatchValidator()
            
            result = openai_validator.validate_match(
                empresa_nome, empresa_descricao, licitacao_objeto, 
                pncp_id, similarity_score, licitacao_itens, empresa_produtos
            )
            
            # Marcar como fallback
            result['provider'] = 'openai_fallback'
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Fallback OpenAI tamb√©m falhou: {e}")
            
            # √öltimo recurso: aprova√ß√£o conservadora baseada no score
            is_valid = similarity_score >= 0.85  # S√≥ aprova scores muito altos
            
            return {
                'is_valid': is_valid,
                'confidence': 0.5,
                'reasoning': f"Fallback: Score {similarity_score:.1%} {'‚â•' if is_valid else '<'} 85%",
                'provider': 'fallback_conservative'
            } 