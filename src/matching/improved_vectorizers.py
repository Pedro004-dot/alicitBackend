#!/usr/bin/env python3
"""
üéØ VETORIZADORES MELHORADOS PARA MATCHING DE ALTA QUALIDADE
Sistema brasileiro aprimorado com an√°lise sem√¢ntica mais rigorosa
"""

import logging
import numpy as np
from typing import List, Optional, Dict, Any, Tuple
import re

from .vectorizers import BrazilianTextVectorizer, calculate_enhanced_similarity
from .improved_matching_config import (
    QualityMatchingConfig, 
    GENERIC_TERMS_BLACKLIST,
    SPECIFIC_TERMS_WHITELIST,
    CATEGORY_THRESHOLDS
)

logger = logging.getLogger(__name__)

class ImprovedBrazilianTextVectorizer(BrazilianTextVectorizer):
    """
    üáßüá∑ Vetorizador brasileiro melhorado com an√°lise de qualidade
    Baseado no BrazilianTextVectorizer mas com filtros de qualidade mais rigorosos
    """
    
    def __init__(self, quality_preset: str = 'balanced'):
        """
        Inicializa vetorizador melhorado
        
        Args:
            quality_preset: 'conservative', 'balanced', 'aggressive', 'ultra_selective'
        """
        super().__init__()
        self.quality_preset = quality_preset
        self.quality_config = QualityMatchingConfig()
        logger.info(f"üéØ Vetorizador brasileiro melhorado inicializado - Preset: {quality_preset}")
    
    def preprocess_text_with_quality_analysis(self, text: str) -> Tuple[str, Dict[str, Any]]:
        """
        Preprocessa texto com an√°lise de qualidade
        
        Returns:
            Tuple[texto_processado, an√°lise_qualidade]
        """
        # Preprocessamento padr√£o
        processed_text = self.preprocess_text(text)
        
        # An√°lise de qualidade
        quality_analysis = {
            'specificity_score': self.quality_config.calculate_specificity_score(text),
            'category': self._detect_business_category(text),
            'has_generic_terms': any(term in text.lower() for term in GENERIC_TERMS_BLACKLIST),
            'has_specific_terms': any(term in text.lower() for term in SPECIFIC_TERMS_WHITELIST),
            'text_length': len(text),
            'complexity_indicators': self._count_complexity_indicators(text)
        }
        
        logger.debug(f"üìä An√°lise qualidade: {quality_analysis['specificity_score']:.2f} - {quality_analysis['category']}")
        
        return processed_text, quality_analysis
    
    def _detect_business_category(self, text: str) -> str:
        """Detecta categoria de neg√≥cio do texto"""
        text_lower = text.lower()
        
        for category, config in CATEGORY_THRESHOLDS.items():
            keyword_matches = sum(1 for keyword in config['keywords'] if keyword in text_lower)
            if keyword_matches >= 1:  # Pelo menos 1 keyword da categoria
                return category
        
        return 'geral'
    
    def _count_complexity_indicators(self, text: str) -> Dict[str, int]:
        """Conta indicadores de complexidade/especificidade"""
        text_lower = text.lower()
        
        return {
            'technical_terms': len(re.findall(r'\b(t√©cnic[oa]|especializ[oa]|certificad[oa]|qualificad[oa])\b', text_lower)),
            'requirements': len(re.findall(r'\b(requisito|exig√™ncia|obrigat√≥rio|necess√°rio)\b', text_lower)),
            'numbers': len(re.findall(r'\d+', text)),
            'regulations': len(re.findall(r'\b(NBR|ISO|ABNT|Lei|Decreto|Portaria)\s*\d*', text)),
            'experience_mentions': len(re.findall(r'\b\d+\s*(anos?|meses?)\b', text_lower))
        }

def calculate_improved_similarity(
    bid_embedding: List[float], 
    company_embedding: List[float], 
    bid_text: str, 
    company_text: str,
    quality_level: str = 'high',
    return_analysis: bool = False
) -> Tuple[float, str, Dict[str, Any]]:
    """
    üéØ C√ÅLCULO OTIMIZADO PARA MATCHES CERTEIROS - N√çVEL HIGH
    
    Implementa an√°lise rigorosa para garantir apenas matches de alta qualidade
    Otimizado para 45-55% de taxa de match com m√°xima precis√£o
    
    Args:
        quality_level: N√≠vel de qualidade ('maximum', 'high', 'medium', 'permissive')
        return_analysis: Se deve retornar an√°lise detalhada
    
    Returns:
        Tuple[score, justificativa, an√°lise_detalhada]
    """
    from .improved_matching_config import get_quality_config, QualityMatchingConfig
    
    # Obter configura√ß√£o espec√≠fica do n√≠vel
    config = get_quality_config(quality_level)
    quality_config = QualityMatchingConfig()
    
    # An√°lise de qualidade dos textos
    vectorizer = ImprovedBrazilianTextVectorizer('balanced')  # Usar preset balanceado
    
    # Preprocessar e analisar textos
    _, bid_analysis = vectorizer.preprocess_text_with_quality_analysis(bid_text)
    _, company_analysis = vectorizer.preprocess_text_with_quality_analysis(company_text)
    
    # Calcular similaridade base usando o m√©todo original
    base_score, base_justification = calculate_enhanced_similarity(
        bid_embedding, company_embedding, bid_text, company_text
    )
    
    # üéØ FILTROS RIGOROSOS PARA N√çVEL HIGH
    quality_adjustments = []
    adjusted_score = base_score
    
    # 1. VERIFICA√á√ÉO DE ESPECIFICIDADE M√çNIMA (CR√çTICO PARA N√çVEL HIGH)
    avg_specificity = (bid_analysis['specificity_score'] + company_analysis['specificity_score']) / 2
    
    if avg_specificity < config.get('min_specificity', 0.5):
        # N√≠vel high exige especificidade m√≠nima de 0.5
        adjusted_score *= config.get('penalty_multiplier', 0.8)
        quality_adjustments.append("‚ùå Textos muito gen√©ricos")
    elif avg_specificity > 0.7:
        adjusted_score *= 1.1  # Bonificar textos altamente espec√≠ficos
        quality_adjustments.append("‚úÖ Textos espec√≠ficos")
    
    # 2. CATEGORIA DE NEG√ìCIO (IMPORTANTE PARA PRECIS√ÉO)
    if bid_analysis['category'] == company_analysis['category'] and bid_analysis['category'] != 'geral':
        adjusted_score *= 1.15  # Bonificar fortemente mesma categoria
        quality_adjustments.append(f"‚úÖ Mesma categoria: {bid_analysis['category']}")
    elif bid_analysis['category'] == 'geral' or company_analysis['category'] == 'geral':
        adjusted_score *= 0.9  # Penalizar categoria muito gen√©rica
    
    # 3. FILTRO DE BLACKLIST RIGOROSO
    bid_lower = bid_text.lower()
    company_lower = company_text.lower()
    
    blacklist_hits = 0
    for term in config['blacklist_terms']:
        if term in bid_lower or term in company_lower:
            blacklist_hits += 1
    
    if blacklist_hits > 2:  # Muitos termos gen√©ricos
        adjusted_score *= 0.75  # Penaliza√ß√£o severa
        quality_adjustments.append("‚ö†Ô∏è Muitos termos gen√©ricos")
    elif blacklist_hits == 0:
        adjusted_score *= 1.05  # Bonificar aus√™ncia de termos gen√©ricos
    
    # 4. BOOST PARA TERMOS T√âCNICOS (N√çVEL HIGH)
    if quality_level == 'high' and 'quality_boost' in config:
        boost_applied = False
        for keyword, boost_value in config['quality_boost'].items():
            if keyword in bid_lower or keyword in company_lower:
                adjusted_score += boost_value
                boost_applied = True
        
        if boost_applied:
            quality_adjustments.append("‚úÖ Termos espec√≠ficos presentes")
    
    # 5. VERIFICA√á√ÉO DE COMPLEXIDADE T√âCNICA
    bid_complexity = sum(bid_analysis['complexity_indicators'].values())
    company_complexity = sum(company_analysis['complexity_indicators'].values())
    
    if bid_complexity >= 3 and company_complexity >= 2:
        adjusted_score *= 1.08  # Bonificar alta complexidade
        quality_adjustments.append("‚úÖ Alta complexidade t√©cnica")
    elif bid_complexity == 0 and company_complexity == 0:
        adjusted_score *= 0.85  # Penalizar baixa complexidade
        quality_adjustments.append("‚ö†Ô∏è Baixa complexidade t√©cnica")
    
    # 6. VERIFICA√á√ÉO ESPECIAL PARA PALAVRAS-CHAVE T√âCNICAS
    tech_keywords = ['desenvolvimento', 'sistema', 'software', 'tecnologia', 'especializado']
    bid_tech_score = sum(1 for keyword in tech_keywords if keyword in bid_lower)
    company_tech_score = sum(1 for keyword in tech_keywords if keyword in company_lower)
    
    if bid_tech_score >= 2 and company_tech_score >= 2:
        # Ambos t√™m perfil t√©cnico forte
        original_similarity = base_score
        # Aplicar boost t√©cnico como mostrado no exemplo anterior
        boost_message = f"Similaridade: {original_similarity:.3f} + boost t√©cnico ({tech_keywords[0]})"
        adjusted_score = min(adjusted_score * 1.1, 1.0)  # Boost t√©cnico
        base_justification = boost_message
    
    # Garantir que score n√£o exceda 1.0
    adjusted_score = min(adjusted_score, 1.0)
    
    # üéØ DECIS√ÉO FINAL PARA N√çVEL HIGH
    should_accept = (
        adjusted_score >= config['threshold_phase1'] and
        avg_specificity >= config.get('min_specificity', 0.5) and
        blacklist_hits <= 2
    )
    
    # Construir categoria de qualidade
    if adjusted_score >= 0.90:
        quality_category = "EXCELENTE"
    elif adjusted_score >= 0.80:
        quality_category = "MUITO_BOM"
    elif adjusted_score >= 0.70:
        quality_category = "BOM"
    elif adjusted_score >= 0.60:
        quality_category = "REGULAR"
    else:
        quality_category = "BAIXO"
    
    # Justificativa melhorada e mais clara
    improved_justification = f"""üéØ AN√ÅLISE MELHORADA: Score base: {base_score:.3f} ‚Üí Score ajustado: {adjusted_score:.3f} Qualidade: {quality_category}

üìä Especificidade:
‚Ä¢ Licita√ß√£o: {bid_analysis['specificity_score']:.2f} ({bid_analysis['category']})
‚Ä¢ Empresa: {company_analysis['specificity_score']:.2f} ({company_analysis['category']})

üîß Ajustes aplicados:
{chr(10).join(quality_adjustments) if quality_adjustments else '‚Ä¢ Nenhum ajuste aplicado'}

{base_justification}""".strip()
    
    # An√°lise detalhada
    detailed_analysis = {
        'base_score': base_score,
        'adjusted_score': adjusted_score,
        'quality_category': quality_category,
        'should_accept': should_accept,
        'bid_analysis': bid_analysis,
        'company_analysis': company_analysis,
        'quality_adjustments': quality_adjustments,
        'avg_specificity': avg_specificity,
        'bid_category': bid_analysis['category'],
        'company_category': company_analysis['category'],
        'config_used': config
    }
    
    if return_analysis:
        return adjusted_score, improved_justification, detailed_analysis
    else:
        return adjusted_score, improved_justification

class QualityFilteredBrazilianVectorizer(ImprovedBrazilianTextVectorizer):
    """
    üéØ Vetorizador com filtro autom√°tico de qualidade
    S√≥ retorna matches que passam pelos crit√©rios de qualidade
    """
    
    def __init__(self, quality_preset: str = 'conservative'):
        """
        Inicializa com preset conservador por padr√£o para m√°xima qualidade
        """
        super().__init__(quality_preset)
        logger.info(f"üõ°Ô∏è Vetorizador com filtro de qualidade inicializado - Preset: {quality_preset}")
    
    def calculate_filtered_similarity(
        self, 
        bid_embedding: List[float], 
        company_embedding: List[float], 
        bid_text: str, 
        company_text: str
    ) -> Optional[Tuple[float, str, Dict[str, Any]]]:
        """
        Calcula similaridade e retorna apenas se passar pelos filtros de qualidade
        
        Returns:
            None se n√£o passar nos filtros, ou (score, justificativa, an√°lise) se passar
        """
        score, justification, analysis = calculate_improved_similarity(
            bid_embedding, company_embedding, bid_text, company_text, self.quality_preset
        )
        
        if analysis['should_accept']:
            logger.debug(f"‚úÖ Match aceito: {score:.3f} - {analysis['quality_category']}")
            return score, justification, analysis
        else:
            logger.debug(f"‚ùå Match rejeitado: {score:.3f} - Baixa qualidade")
            return None

def get_vectorizer_for_quality_level(quality_level: str, vectorizer_type: str = "brazilian") -> ImprovedBrazilianTextVectorizer:
    """
    Factory function para criar vetorizador baseado no n√≠vel de qualidade desejado
    
    Args:
        quality_level: 'maximum', 'high', 'medium', 'permissive'
        vectorizer_type: 'brazilian', 'hybrid', etc. (sempre retorna brasileiro otimizado)
    """
    preset_mapping = {
        'maximum': 'ultra_selective',
        'high': 'conservative', 
        'medium': 'balanced',
        'permissive': 'aggressive'
    }
    
    preset = preset_mapping.get(quality_level, 'balanced')
    
    # Para n√≠vel high, usar vectorizer brasileiro otimizado
    if quality_level == 'high':
        return ImprovedBrazilianTextVectorizer('balanced')  # Preset balanceado para high
    elif quality_level == 'maximum':
        return QualityFilteredBrazilianVectorizer(preset)
    else:
        return ImprovedBrazilianTextVectorizer(preset) 