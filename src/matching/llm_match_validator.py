#!/usr/bin/env python3
"""
ğŸ¤– VALIDADOR LLM PARA MATCHES DE ALTA QUALIDADE
Sistema de validaÃ§Ã£o final para matches acima de 80% usando IA generativa
"""

import os
import json
from typing import Dict, Any, List, Tuple, Optional
import logging
from openai import OpenAI

logger = logging.getLogger(__name__)

class LLMMatchValidator:
    """
    ğŸ¯ Validador inteligente para matches de alta qualidade
    
    Analisa matches acima de 80% usando LLM para determinar se realmente
    fazem sentido do ponto de vista de negÃ³cio e competÃªncia empresarial.
    """
    
    def __init__(self):
        """Inicializar o validador com configuraÃ§Ãµes"""
        self.openai_client = None
        self._setup_llm()
        
        # Thresholds para validaÃ§Ã£o
        self.HIGH_SCORE_THRESHOLD = 0.80  # Acima de 80% vai para validaÃ§Ã£o LLM
        self.LLM_CONFIDENCE_THRESHOLD = 0.75  # ConfianÃ§a mÃ­nima do LLM para aprovar
        
    def _setup_llm(self):
        """Configurar cliente OpenAI"""
        try:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.openai_client = OpenAI(api_key=api_key)
                logger.info("âœ… Cliente OpenAI configurado para validaÃ§Ã£o LLM")
            else:
                logger.warning("âš ï¸ OPENAI_API_KEY nÃ£o encontrada - validaÃ§Ã£o LLM desabilitada")
        except Exception as e:
            logger.error(f"âŒ Erro ao configurar OpenAI: {e}")
    
    def should_validate_with_llm(self, score: float) -> bool:
        """Determina se o match precisa de validaÃ§Ã£o LLM"""
        return score >= self.HIGH_SCORE_THRESHOLD and self.openai_client is not None
    
    def validate_match(
        self, 
        empresa_nome: str,
        empresa_descricao: str,
        licitacao_objeto: str,
        pncp_id: str,
        similarity_score: float
    ) -> Dict[str, Any]:
        """
        ğŸ¤– ValidaÃ§Ã£o inteligente de match usando LLM
        
        Returns:
            Dict com resultado da validaÃ§Ã£o:
            {
                'is_valid': bool,
                'confidence': float,
                'reasoning': str,
                'recommendation': str,
                'llm_used': bool
            }
        """
        
        if not self.should_validate_with_llm(similarity_score):
            return {
                'is_valid': True,
                'confidence': similarity_score,
                'reasoning': f'Score {similarity_score:.1%} abaixo do threshold LLM ({self.HIGH_SCORE_THRESHOLD:.1%})',
                'recommendation': 'Aprovado sem validaÃ§Ã£o LLM',
                'llm_used': False
            }
        
        if not self.openai_client:
            logger.warning("âš ï¸ LLM nÃ£o disponÃ­vel - aprovando match automaticamente")
            return {
                'is_valid': True,
                'confidence': similarity_score,
                'reasoning': 'LLM indisponÃ­vel - validaÃ§Ã£o automÃ¡tica',
                'recommendation': 'Aprovado por fallback',
                'llm_used': False
            }
        
        try:
            # Prompt especializado para validaÃ§Ã£o de matches
            prompt = self._build_validation_prompt(
                empresa_nome, empresa_descricao, licitacao_objeto, pncp_id, similarity_score
            )
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",  # Modelo otimizado para custo-efetividade
                messages=[
                    {
                        "role": "system", 
                        "content": self._get_system_prompt()
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.1,  # Baixa criatividade para anÃ¡lise objetiva
                max_tokens=500,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # Validar estrutura da resposta
            validation_result = self._parse_llm_response(result, similarity_score)
            
            logger.info(f"ğŸ¤– LLM validaÃ§Ã£o: {empresa_nome} vs {pncp_id} = {validation_result['is_valid']} (conf: {validation_result['confidence']:.1%})")
            
            return validation_result
            
        except Exception as e:
            logger.error(f"âŒ Erro na validaÃ§Ã£o LLM: {e}")
            
            # Fallback: aprovar automaticamente em caso de erro
            return {
                'is_valid': True,
                'confidence': similarity_score * 0.9,  # Penalizar levemente por falha LLM
                'reasoning': f'Erro na validaÃ§Ã£o LLM: {str(e)} - Aprovado por fallback',
                'recommendation': 'Verificar manualmente',
                'llm_used': False
            }
    
    def _get_system_prompt(self) -> str:
        """Prompt do sistema para o LLM"""
        return """VocÃª Ã© um especialista em anÃ¡lise de licitaÃ§Ãµes pÃºblicas brasileiras e competÃªncias empresariais.

Sua tarefa Ã© validar se um match entre uma empresa e uma licitaÃ§Ã£o faz sentido do ponto de vista de negÃ³cio e capacidade tÃ©cnica.

CRITÃ‰RIOS DE AVALIAÃ‡ÃƒO:
1. **CompetÃªncia TÃ©cnica**: A empresa tem capacidade de executar o objeto da licitaÃ§Ã£o?
2. **Ãrea de AtuaÃ§Ã£o**: O ramo de atividade da empresa Ã© compatÃ­vel com o serviÃ§o/produto licitado?
3. **ExperiÃªncia Relevante**: A descriÃ§Ã£o da empresa indica experiÃªncia no setor?
4. **Viabilidade Comercial**: Faz sentido comercial a empresa participar desta licitaÃ§Ã£o?

RESPONDA SEMPRE EM JSON com esta estrutura:
{
    "is_valid": boolean,
    "confidence": number (0.0 a 1.0),
    "reasoning": "explicaÃ§Ã£o detalhada da anÃ¡lise",
    "recommendation": "RECOMENDADO | NÃƒO_RECOMENDADO | REVISAR_MANUALMENTE"
}

Seja rigoroso: prefira reprovar matches duvidosos a aprovar matches irrelevantes."""
    
    def _build_validation_prompt(
        self, 
        empresa_nome: str, 
        empresa_descricao: str, 
        licitacao_objeto: str, 
        pncp_id: str, 
        similarity_score: float
    ) -> str:
        """ConstrÃ³i o prompt de validaÃ§Ã£o"""
        
        return f"""ANÃLISE DE MATCH PARA VALIDAÃ‡ÃƒO:

**EMPRESA:**
- Nome: {empresa_nome}
- DescriÃ§Ã£o: {empresa_descricao}

**LICITAÃ‡ÃƒO:**
- PNCP ID: {pncp_id}
- Objeto: {licitacao_objeto}

**SCORE SEMÃ‚NTICO:** {similarity_score:.1%}

PERGUNTA: Esta empresa tem competÃªncia e capacidade real para executar este objeto licitado? 
O match faz sentido do ponto de vista de negÃ³cio e adequaÃ§Ã£o tÃ©cnica?

Analise cuidadosamente se hÃ¡ compatibilidade real entre:
- As competÃªncias/experiÃªncia da empresa
- Os requisitos tÃ©cnicos da licitaÃ§Ã£o
- A viabilidade comercial do match

Responda em JSON conforme especificado."""
    
    def _parse_llm_response(self, llm_result: Dict, original_score: float) -> Dict[str, Any]:
        """Parseia e valida a resposta do LLM"""
        
        try:
            is_valid = llm_result.get('is_valid', False)
            confidence = float(llm_result.get('confidence', 0.0))
            reasoning = llm_result.get('reasoning', 'Sem justificativa fornecida')
            recommendation = llm_result.get('recommendation', 'REVISAR_MANUALMENTE')
            
            # Aplicar threshold de confianÃ§a
            if confidence < self.LLM_CONFIDENCE_THRESHOLD:
                is_valid = False
                reasoning += f" | ConfianÃ§a LLM ({confidence:.1%}) abaixo do mÃ­nimo ({self.LLM_CONFIDENCE_THRESHOLD:.1%})"
            
            # Garantir que confianÃ§a nÃ£o seja maior que score original
            confidence = min(confidence, original_score)
            
            return {
                'is_valid': is_valid,
                'confidence': confidence,
                'reasoning': reasoning,
                'recommendation': recommendation,
                'llm_used': True
            }
            
        except Exception as e:
            logger.error(f"âŒ Erro ao parsear resposta LLM: {e}")
            
            return {
                'is_valid': False,
                'confidence': 0.0,
                'reasoning': f'Erro ao processar resposta LLM: {str(e)}',
                'recommendation': 'REVISAR_MANUALMENTE',
                'llm_used': True
            }
    
    def validate_matches_batch(self, matches: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Valida mÃºltiplos matches em lote
        
        Args:
            matches: Lista de dicts com campos:
                - empresa_nome, empresa_descricao
                - licitacao_objeto, pncp_id  
                - score_similaridade
        
        Returns:
            Lista de matches com validaÃ§Ã£o LLM aplicada
        """
        
        validated_matches = []
        llm_validations_count = 0
        
        for match in matches:
            try:
                score = float(match.get('score_similaridade', 0))
                
                # Aplicar validaÃ§Ã£o LLM se necessÃ¡rio
                validation = self.validate_match(
                    empresa_nome=match.get('empresa_nome', ''),
                    empresa_descricao=match.get('empresa_descricao', ''),
                    licitacao_objeto=match.get('licitacao_objeto', ''),
                    pncp_id=match.get('pncp_id', ''),
                    similarity_score=score
                )
                
                # Adicionar resultado da validaÃ§Ã£o ao match
                enhanced_match = match.copy()
                enhanced_match.update({
                    'llm_validation': validation,
                    'final_score': validation['confidence'],
                    'is_recommended': validation['is_valid']
                })
                
                # SÃ³ adicionar Ã  lista se for vÃ¡lido
                if validation['is_valid']:
                    validated_matches.append(enhanced_match)
                else:
                    logger.info(f"ğŸš« Match rejeitado pela validaÃ§Ã£o LLM: {match.get('empresa_nome')} vs {match.get('pncp_id')}")
                
                if validation['llm_used']:
                    llm_validations_count += 1
                    
            except Exception as e:
                logger.error(f"âŒ Erro ao validar match: {e}")
                # Em caso de erro, incluir o match original sem validaÃ§Ã£o
                validated_matches.append(match)
        
        logger.info(f"ğŸ¤– ValidaÃ§Ã£o LLM: {llm_validations_count} matches analisados, {len(validated_matches)}/{len(matches)} aprovados")
        
        return validated_matches


# InstÃ¢ncia global do validador
llm_validator = LLMMatchValidator()


def validate_high_score_match(
    empresa_nome: str,
    empresa_descricao: str, 
    licitacao_objeto: str,
    pncp_id: str,
    similarity_score: float
) -> Dict[str, Any]:
    """
    ğŸ¯ FunÃ§Ã£o de conveniÃªncia para validar um match individual
    
    Wrapper around LLMMatchValidator.validate_match()
    """
    return llm_validator.validate_match(
        empresa_nome, empresa_descricao, licitacao_objeto, 
        pncp_id, similarity_score
    )


if __name__ == "__main__":
    # Teste com exemplos reais ruins
    validator = LLMMatchValidator()
    
    # Exemplo 1: Software vs ManutenÃ§Ã£o de VeÃ­culos (deveria ser rejeitado)
    result1 = validator.validate_match(
        empresa_nome="InfinitiFy",
        empresa_descricao="Empresa especialista no fornecimento de softwares, sistemas de redes, banco de dados, inteligencia artificial.",
        licitacao_objeto="Registro de preÃ§os para a prestaÃ§Ã£o de serviÃ§os de manutenÃ§Ã£o em veÃ­culos leves, vans, minivans, micro-Ã´nibus e caminhÃµes, sendo: mecÃ¢nica, elÃ©trica e eletrÃ´nica, funilaria, lanternagem e pintura",
        pncp_id="87613196000178-1-000045/2025",
        similarity_score=0.892
    )
    
    print("ğŸ§ª TESTE 1 - Software vs VeÃ­culos:")
    print(f"âœ… VÃ¡lido: {result1['is_valid']}")
    print(f"ğŸ“Š ConfianÃ§a: {result1['confidence']:.1%}")
    print(f"ğŸ’­ RaciocÃ­nio: {result1['reasoning']}")
    print(f"ğŸ¯ RecomendaÃ§Ã£o: {result1['recommendation']}")
    print()
    
    # Exemplo 2: Match que deveria ser aprovado
    result2 = validator.validate_match(
        empresa_nome="TechSoft Solutions",
        empresa_descricao="Empresa especializada em desenvolvimento de software de gestÃ£o pÃºblica, sistemas de ponto eletrÃ´nico e controle de acesso, com experiÃªncia em implementaÃ§Ã£o de soluÃ§Ãµes tecnolÃ³gicas para Ã³rgÃ£os pÃºblicos.",
        licitacao_objeto="ContrataÃ§Ã£o de empresa especializada na prestaÃ§Ã£o de serviÃ§os de implantaÃ§Ã£o de sistema de gestÃ£o administrativa de ponto eletrÃ´nico facial e controle de acesso de funcionÃ¡rios",
        pncp_id="19904298000192-1-000012/2025",
        similarity_score=0.850
    )
    
    print("ğŸ§ª TESTE 2 - Software vs Software (match bom):")
    print(f"âœ… VÃ¡lido: {result2['is_valid']}")
    print(f"ğŸ“Š ConfianÃ§a: {result2['confidence']:.1%}")
    print(f"ğŸ’­ RaciocÃ­nio: {result2['reasoning']}")
    print(f"ğŸ¯ RecomendaÃ§Ã£o: {result2['recommendation']}") 