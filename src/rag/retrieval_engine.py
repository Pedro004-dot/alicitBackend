# Retrieval engine module 

import openai
import logging
from typing import List, Dict, Any, Optional
import time
import numpy as np

logger = logging.getLogger(__name__)

class RetrievalEngine:
    """Engine de retrieval com reranking"""
    
    def __init__(self, openai_api_key: str):
        self.openai_client = openai.OpenAI(api_key=openai_api_key)
        
        # Modelo de reranking
        self.reranker = None
        self._load_reranker()
    
    def _load_reranker(self):
        """Reranking desabilitado - usando apenas similaridade sem√¢ntica"""
        logger.info("‚ö†Ô∏è  Reranking com CrossEncoder desabilitado (removido sentence-transformers)")
        logger.info("üí° Usando apenas scores de similaridade sem√¢ntica para ordena√ß√£o")
        self.reranker = None
    
    def rerank_chunks(self, query: str, chunks: List[Dict], top_k: int = 8) -> List[Dict]:
        """Ordena chunks por similaridade sem√¢ntica (reranking desabilitado)"""
        try:
            logger.info(f"üîÑ Ordenando {len(chunks)} chunks por similaridade sem√¢ntica")
            
            # Usar score de similaridade existente como score final
            for chunk in chunks:
                original_score = chunk.get('hybrid_score', chunk.get('similarity_score', 0))
                chunk['final_score'] = original_score
                chunk['rerank_score'] = None  # Reranking desabilitado
            
            # Ordenar por score de similaridade
            sorted_chunks = sorted(chunks, key=lambda x: x['final_score'], reverse=True)
            
            logger.info(f"‚úÖ Chunks ordenados por similaridade, retornando top {top_k}")
            return sorted_chunks[:top_k]
            
        except Exception as e:
            logger.error(f"‚ùå Erro na ordena√ß√£o: {e}")
            return chunks[:top_k]
    
    def generate_response(self, query: str, context_chunks: List[Dict], 
                         licitacao_info: Optional[Dict] = None) -> Dict[str, Any]:
        """Gera resposta usando OpenAI GPT-4"""
        try:
            logger.info("ü§ñ Gerando resposta com GPT-4...")
            
            # Construir contexto
            context_text = self._build_context(context_chunks, licitacao_info)
            
            # Prompt otimizado para licita√ß√µes
            system_prompt = """Voc√™ √© um especialista em an√°lise de licita√ß√µes p√∫blicas brasileiras. 
            Sua fun√ß√£o √© responder perguntas sobre documentos de licita√ß√£o de forma precisa e detalhada.

            INSTRU√á√ïES:
            1. Use APENAS as informa√ß√µes fornecidas no contexto
            2. Seja espec√≠fico e cite n√∫meros de p√°ginas quando dispon√≠vel
            3. Se a informa√ß√£o n√£o estiver no contexto, diga claramente
            4. Formate valores monet√°rios em reais (R$)
            5. Mencione artigos, cl√°usulas e se√ß√µes espec√≠ficas quando relevantes
            6. Mantenha tom profissional e t√©cnico
            """
            
            user_prompt = f"""
            CONTEXTO DOS DOCUMENTOS:
            {context_text}
            
            PERGUNTA: {query}
            
            Responda de forma completa e estruturada, citando as fontes espec√≠ficas do documento.
            """
            
            # Fazer chamada para OpenAI
            start_time = time.time()
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",  # Mais barato que gpt-4
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,  # Baixa para respostas mais determin√≠sticas
                max_tokens=1500
            )
            
            response_time = time.time() - start_time
            
            # Extrair resposta
            answer = response.choices[0].message.content
            
            # Calcular custos aproximados (pre√ßos de janeiro 2025)
            input_tokens = len(user_prompt.split()) * 1.3  # Aproxima√ß√£o
            output_tokens = len(answer.split()) * 1.3
            
            # GPT-4o-mini: $0.00015/1K input, $0.0006/1K output
            cost = (input_tokens * 0.00015 / 1000) + (output_tokens * 0.0006 / 1000)
            
            result = {
                'answer': answer,
                'chunks_used': len(context_chunks),
                'response_time': round(response_time, 2),
                'cost_usd': round(cost, 6),
                'model': "gpt-4o-mini",
                'sources': self._extract_sources(context_chunks)
            }
            
            logger.info(f"‚úÖ Resposta gerada em {response_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar resposta: {e}")
            return {
                'answer': f"Erro ao gerar resposta: {str(e)}",
                'error': True
            }
    
    def _build_context(self, chunks: List[Dict], licitacao_info: Optional[Dict] = None) -> str:
        """Constr√≥i contexto para o LLM"""
        context_parts = []
        
        # Adicionar informa√ß√µes da licita√ß√£o se dispon√≠vel
        if licitacao_info:
            context_parts.append(f"""
            INFORMA√á√ïES DA LICITA√á√ÉO:
            - Objeto: {licitacao_info.get('objeto_compra', 'N/A')}
            - Modalidade: {licitacao_info.get('modalidade_nome', 'N/A')}
            - Valor Total Estimado: R$ {licitacao_info.get('valor_total_estimado', 'N/A')}
            - √ìrg√£o: {licitacao_info.get('orgao_entidade', 'N/A')}
            - UF: {licitacao_info.get('uf', 'N/A')}
            """)
        
        # Adicionar chunks do documento
        for i, chunk in enumerate(chunks, 1):
            context_parts.append(f"""
            TRECHO {i} (P√°gina {chunk.get('page_number', 'N/A')}):
            {chunk['text']}
            """)
        
        return "\n".join(context_parts)
    
    def _extract_sources(self, chunks: List[Dict]) -> List[Dict]:
        """Extrai informa√ß√µes de fonte dos chunks"""
        sources = []
        for chunk in chunks:
            source = {
                'page_number': chunk.get('page_number'),
                'chunk_type': chunk.get('chunk_type'),
                'section_title': chunk.get('section_title'),
                'score': chunk.get('final_score', chunk.get('hybrid_score', 0))
            }
            sources.append(source)
        
        return sources 