# Retrieval engine module 

import openai
import logging
from typing import List, Dict, Any, Optional
import time
import numpy as np

logger = logging.getLogger(__name__)

class RetrievalEngine:
    """Engine de retrieval com reranking"""
    
    def __init__(self, openai_api_key: str):
        self.openai_client = openai.OpenAI(api_key=openai_api_key)
        
        # Modelo de reranking
        self.reranker = None
        self._load_reranker()
    
    def _load_reranker(self):
        """Reranking desabilitado - usando apenas similaridade sem√¢ntica"""
        logger.info("‚ö†Ô∏è  Reranking com CrossEncoder desabilitado (removido sentence-transformers)")
        logger.info("üí° Usando apenas scores de similaridade sem√¢ntica para ordena√ß√£o")
        self.reranker = None
    
    def rerank_chunks(self, query: str, chunks: List[Dict], top_k: int = 8) -> List[Dict]:
        """Ordena chunks por similaridade sem√¢ntica (reranking desabilitado)"""
        try:
            logger.info(f"üîÑ Ordenando {len(chunks)} chunks por similaridade sem√¢ntica")
            
            # Usar score de similaridade existente como score final
            for chunk in chunks:
                original_score = chunk.get('hybrid_score', chunk.get('similarity_score', 0))
                chunk['final_score'] = original_score
                chunk['rerank_score'] = None  # Reranking desabilitado
            
            # Ordenar por score de similaridade
            sorted_chunks = sorted(chunks, key=lambda x: x['final_score'], reverse=True)
            
            logger.info(f"‚úÖ Chunks ordenados por similaridade, retornando top {top_k}")
            return sorted_chunks[:top_k]
            
        except Exception as e:
            logger.error(f"‚ùå Erro na ordena√ß√£o: {e}")
            return chunks[:top_k]
    
    def generate_response(self, query: str, context_chunks: List[Dict], 
                         licitacao_info: Optional[Dict] = None) -> Dict[str, Any]:
        """Gera resposta usando OpenAI com fallback autom√°tico: gpt-4o-mini -> gpt-4o"""
        try:
            logger.info("ü§ñ Gerando resposta com OpenAI (4o-mini -> 4o fallback)...")
            
            # Construir contexto
            context_text = self._build_context(context_chunks, licitacao_info)
            
            # Prompt otimizado para licita√ß√µes
            system_prompt = """Voc√™ √© um especialista s√™nior em licita√ß√µes p√∫blicas brasileiras com 15+ anos de experi√™ncia em an√°lise de editais, participa√ß√£o em concorr√™ncias e assessoria jur√≠dica licitat√≥ria.
            ## SEU PAPEL:
            Analisar documentos licitat√≥rios e fornecer insights estrat√©gicos para maximizar as chances de sucesso em licita√ß√µes p√∫blicas.

            ## CONHECIMENTO ESPECIALIZADO:
            - Lei 8.666/93, Lei 14.133/21 (Nova Lei de Licita√ß√µes), Decreto 10.024/19
            - Modalidades: Preg√£o, Concorr√™ncia, Tomada de Pre√ßos, Convite, RDC, Di√°logo Competitivo
            - Habilita√ß√£o t√©cnica, econ√¥mico-financeira, jur√≠dica e regularidade fiscal
            - Crit√©rios de julgamento, impugna√ß√µes, recursos administrativos
            - An√°lise de riscos contratuais e cl√°usulas restritivas

            ## INSTRU√á√ïES DE AN√ÅLISE:

            ### 1. PRECIS√ÉO DOCUMENTAL
            - Use EXCLUSIVAMENTE informa√ß√µes do contexto fornecido
            - Cite SEMPRE: p√°gina, se√ß√£o, item, subitem ou cl√°usula espec√≠fica
            - Para valores: identifique se s√£o estimados, m√°ximos ou de refer√™ncia
            - Destaque prazos, datas e condi√ß√µes temporais cr√≠ticas

            ### 2. AN√ÅLISE ESTRAT√âGICA
            - Identifique requisitos obrigat√≥rios vs desej√°veis
            - Destaque potenciais impedimentos ou dificuldades
            - Sinalize cl√°usulas que podem restringir competitividade
            - Avalie complexidade t√©cnica e exig√™ncias espec√≠ficas

            ### 3. ALERTAS CR√çTICOS
            - Marque com ‚ö†Ô∏è ALERTA quando identificar:
            * Exig√™ncias possivelmente restritivas ou desproporcionais
            * Prazos apertados ou incompat√≠veis
            * Contradi√ß√µes entre documentos
            * Crit√©rios subjetivos de julgamento
            * Cl√°usulas que favore√ßam empresa espec√≠fica

            ### 4. FORMATA√á√ÉO ESTRUTURADA
            - Destaque informa√ß√µes cr√≠ticas em **negrito**
            - Liste requisitos em bullet points
            - Separe an√°lise t√©cnica de an√°lise comercial
            - Seja claro e objetivo, n√£o seja redundante
            - Sua estrutura deve ser como uma resposta de um especialista em licita√ß√µes, com t√≠tulos, subt√≠tulos, listas, etc.

            ### 5. QUANDO N√ÉO SOUBER
            Seja transparente: "Esta informa√ß√£o n√£o est√° dispon√≠vel nos documentos fornecidos. Recomendo consultar [documento espec√≠fico] ou contatar o √≥rg√£o licitante."

            ## FOCO NOS RESULTADOS:
            Sua an√°lise deve permitir que a empresa tome decis√µes informadas sobre:
            - Viabilidade de participa√ß√£o
            - Estrat√©gia de proposta t√©cnica e comercial  
            - Cronograma de prepara√ß√£o
            - Recursos necess√°rios para habilita√ß√£o
            """
            
            user_prompt = f"""
            CONTEXTO DOS DOCUMENTOS:
            {context_text}
            
            PERGUNTA: {query}
            
            Responda de forma completa e estruturada, citando as fontes espec√≠ficas do documento.
            """
            
            # üéØ TENTATIVA 1: gpt-4o-mini (modelo prim√°rio)
            start_time = time.time()
            model_used = "gpt-4o-mini"
            
            try:
                logger.info("üöÄ Tentando gpt-4o-mini (modelo prim√°rio)...")
                response = self._make_openai_request(system_prompt, user_prompt, model_used)
                logger.info("‚úÖ gpt-4o-mini respondeu com sucesso!")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è gpt-4o-mini falhou: {e}")
                logger.info("üîÑ Fazendo fallback para gpt-4o...")
                
                # üéØ TENTATIVA 2: gpt-4o (fallback)
                model_used = "gpt-4o"
                try:
                    response = self._make_openai_request(system_prompt, user_prompt, model_used)
                    logger.info("‚úÖ gpt-4o (fallback) respondeu com sucesso!")
                    
                except Exception as e2:
                    logger.error(f"‚ùå gpt-4o tamb√©m falhou: {e2}")
                    logger.info("üîÑ Tentando gpt-3.5-turbo como √∫ltimo recurso...")
                    
                    # üéØ TENTATIVA 3: gpt-3.5-turbo (√∫ltimo recurso)
                    model_used = "gpt-3.5-turbo"
                    response = self._make_openai_request(system_prompt, user_prompt, model_used)
                    logger.info("‚úÖ gpt-3.5-turbo (√∫ltimo recurso) respondeu!")
            
            response_time = time.time() - start_time
            
            # Extrair resposta
            answer = response.choices[0].message.content
            
            # Calcular custos aproximados baseado no modelo usado
            input_tokens = len(user_prompt.split()) * 1.3  # Aproxima√ß√£o
            output_tokens = len(answer.split()) * 1.3
            cost = self._calculate_cost(model_used, input_tokens, output_tokens)
            
            result = {
                'answer': answer,
                'chunks_used': len(context_chunks),
                'response_time': round(response_time, 2),
                'cost_usd': round(cost, 6),
                'model': model_used,
                'sources': self._extract_sources(context_chunks)
            }
            
            logger.info(f"‚úÖ Resposta gerada em {response_time:.2f}s usando {model_used}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Todos os modelos falharam: {e}")
            return {
                'answer': f"Erro ao gerar resposta: {str(e)}",
                'error': True
            }
    
    def _make_openai_request(self, system_prompt: str, user_prompt: str, model: str):
        """Faz requisi√ß√£o para OpenAI com modelo espec√≠fico"""
        return self.openai_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,  # Baixa para respostas mais determin√≠sticas
            max_tokens=1500
        )
    
    def _calculate_cost(self, model: str, input_tokens: float, output_tokens: float) -> float:
        """Calcula custo baseado no modelo usado"""
        # Pre√ßos por 1K tokens (janeiro 2025)
        pricing = {
            "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
            "gpt-4o": {"input": 0.005, "output": 0.015},
            "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002}
        }
        
        if model in pricing:
            rates = pricing[model]
            return (input_tokens * rates["input"] / 1000) + (output_tokens * rates["output"] / 1000)
        else:
            # Fallback para gpt-3.5-turbo pricing
            return (input_tokens * 0.0015 / 1000) + (output_tokens * 0.002 / 1000)
    
    def _build_context(self, chunks: List[Dict], licitacao_info: Optional[Dict] = None) -> str:
        """Constr√≥i contexto para o LLM"""
        context_parts = []
        
        # Adicionar informa√ß√µes da licita√ß√£o se dispon√≠vel
        if licitacao_info:
            context_parts.append(f"""
            INFORMA√á√ïES DA LICITA√á√ÉO:
            - Objeto: {licitacao_info.get('objeto_compra', 'N/A')}
            - Modalidade: {licitacao_info.get('modalidade_nome', 'N/A')}
            - Valor Total Estimado: R$ {licitacao_info.get('valor_total_estimado', 'N/A')}
            - √ìrg√£o: {licitacao_info.get('orgao_entidade', 'N/A')}
            - UF: {licitacao_info.get('uf', 'N/A')}
            """)
        
        # Adicionar chunks do documento
        for i, chunk in enumerate(chunks, 1):
            context_parts.append(f"""
            TRECHO {i} (P√°gina {chunk.get('page_number', 'N/A')}):
            {chunk['text']}
            """)
        
        return "\n".join(context_parts)
    
    def _extract_sources(self, chunks: List[Dict]) -> List[Dict]:
        """Extrai informa√ß√µes de fonte dos chunks"""
        sources = []
        for chunk in chunks:
            source = {
                'page_number': chunk.get('page_number'),
                'chunk_type': chunk.get('chunk_type'),
                'section_title': chunk.get('section_title'),
                'score': chunk.get('final_score', chunk.get('hybrid_score', 0))
            }
            sources.append(source)
        
        return sources 