"""
Rotas para opera√ß√µes de sistema
"""
from flask import Blueprint, request, jsonify
from controllers.system_controller import SystemController
import logging
from datetime import datetime
import threading
import time

logger = logging.getLogger(__name__)

# Criar blueprint para sistema
system_routes = Blueprint('system', __name__)

# Instanciar controller
controller = SystemController()

# ====== ROTAS DE SISTEMA ======

@system_routes.route('/api/health', methods=['GET'])
def health_check():
    """
    GET /api/health - Health check do sistema
    
    DESCRI√á√ÉO:
    - Verifica√ß√£o geral de sa√∫de de toda a aplica√ß√£o
    - Testa conectividade com banco de dados, APIs externas
    - Usado para monitoramento autom√°tico e alertas
    
    RETORNA:
    - Status geral do sistema (healthy/degraded/unhealthy)
    - Detalhes de cada componente (database, supabase, etc.)
    - Timestamp da verifica√ß√£o e tempo de resposta
    - Vers√£o da aplica√ß√£o e informa√ß√µes do ambiente
    """
    return controller.health_check()

@system_routes.route('/api/status', methods=['GET'])
def get_system_status():
    """
    GET /api/status - Status geral do sistema
    
    DESCRI√á√ÉO:
    - Informa√ß√µes detalhadas sobre o estado atual do sistema
    - Inclui estat√≠sticas de uso, performance e recursos
    - Usado para dashboards administrativos
    
    RETORNA:
    - Estat√≠sticas de uso da aplica√ß√£o
    - Informa√ß√µes sobre processos em execu√ß√£o
    - M√©tricas de performance e mem√≥ria
    - Status dos servi√ßos dependentes
    """
    return controller.get_system_status()

@system_routes.route('/api/status/daily-bids', methods=['GET'])
def get_daily_bids_status():
    """
    GET /api/status/daily-bids - Status da busca di√°ria
    
    DESCRI√á√ÉO:
    - Monitora o processo autom√°tico de busca di√°ria de licita√ß√µes
    - Usado pelo frontend para mostrar status em tempo real
    - Inclui informa√ß√µes sobre √∫ltima execu√ß√£o e pr√≥xima
    
    RETORNA:
    - Status atual do processo (running/idle/error)
    - Timestamp da √∫ltima execu√ß√£o bem-sucedida
    - Quantidade de licita√ß√µes encontradas na √∫ltima busca
    - Pr√≥xima execu√ß√£o programada
    """
    return controller.get_daily_bids_status()

@system_routes.route('/api/status/reevaluate', methods=['GET'])
def get_reevaluate_status():
    """
    GET /api/status/reevaluate - Status da reavalia√ß√£o
    
    DESCRI√á√ÉO:
    - Monitora o processo de reavalia√ß√£o de matches existentes
    - Usado pelo frontend para acompanhar progresso em tempo real
    - Mostra estat√≠sticas de reprocessamento de dados
    
    RETORNA:
    - Status atual da reavalia√ß√£o (running/idle/error)
    - Progresso atual (% conclu√≠do, registros processados)
    - Timestamp de in√≠cio e estimativa de conclus√£o
    - Estat√≠sticas de matches atualizados
    """
    return controller.get_reevaluate_status()

@system_routes.route('/api/config/options', methods=['GET'])
def get_config_options():
    """
    GET /api/config/options - Op√ß√µes de configura√ß√£o do sistema
    
    DESCRI√á√ÉO:
    - Lista todas as configura√ß√µes dispon√≠veis do sistema
    - Usado para interface administrativa de configura√ß√£o
    - Inclui valores atuais e op√ß√µes dispon√≠veis
    
    RETORNA:
    - Configura√ß√µes de busca autom√°tica (frequ√™ncia, filtros)
    - Par√¢metros do algoritmo de matching
    - Configura√ß√µes de notifica√ß√µes e alertas
    - Limites de API e timeouts
    """
    return controller.get_config_options()

@system_routes.route('/api/search-new-bids', methods=['POST'], strict_slashes=False)
def search_new_bids():
    """
    POST /api/search-new-bids - Iniciar busca de novas licita√ß√µes
    
    DESCRI√á√ÉO:
    - Inicia manualmente o processo de busca de novas licita√ß√µes
    - Usado pelo frontend no bot√£o "Buscar Novas Licita√ß√µes"
    - Processo ass√≠ncrono que roda em background
    
    PAR√ÇMETROS (Body JSON):
    - force: For√ßar nova busca mesmo se j√° executada hoje
    - filters: Filtros espec√≠ficos para a busca (opcional)
    - limit: Limite de registros a buscar (opcional)
    
    RETORNA:
    - Confirma√ß√£o de in√≠cio do processo
    - ID do processo para acompanhamento
    - Estimativa de tempo de execu√ß√£o
    """
    return controller.search_new_bids()

# üî• NOVA ROTA: Busca semanal com valida√ß√£o LLM QWEN
@system_routes.route('/api/search-weekly-bids', methods=['POST', 'GET'], strict_slashes=False)
def search_weekly_bids():
    """
    POST/GET /api/search-weekly-bids - Buscar licita√ß√µes da √∫ltima semana com QWEN LLM
    
    DESCRI√á√ÉO:
    - Busca licita√ß√µes dos √∫ltimos 7 dias no PNCP
    - Usa modelo QWEN 2.5:7B para valida√ß√£o de matches
    - APENAS matches aprovados pelo LLM s√£o salvos no Supabase
    - Processo otimizado com cache Redis local
    
    PAR√ÇMETROS (Body JSON - todos opcionais):
    {
        "vectorizer": "brazilian",     // tipo de vetorizador (brazilian, hybrid, openai)
        "clear_matches": true,         // limpar matches existentes antes
        "enable_llm": true,           // valida√ß√£o LLM (padr√£o: true)
        "max_pages": 10               // limite de p√°ginas por UF
    }
    
    RETORNA:
    {
        "success": true,
        "process_id": "weekly_search_20250125_143022",
        "message": "Busca semanal iniciada com valida√ß√£o LLM QWEN",
        "config": {
            "period": "√∫ltimos 7 dias",
            "llm_model": "qwen2.5:7b",
            "vectorizer": "brazilian",
            "estimated_duration": "15-30 minutos"
        }
    }
    """
    try:
        # Lidar com GET e POST
        if request.method == 'GET':
            data = {
                'vectorizer': request.args.get('vectorizer', 'brazilian'),
                'clear_matches': request.args.get('clear_matches', 'false').lower() == 'true',
                'enable_llm': request.args.get('enable_llm', 'true').lower() == 'true',
                'max_pages': int(request.args.get('max_pages', '10'))
            }
        else:
            # POST - Tentar m√∫ltiplas formas de obter dados da requisi√ß√£o
            data = {}
            
            # Primeira tentativa: JSON normal
            try:
                data = request.get_json() or {}
            except Exception:
                # Segunda tentativa: for√ßar parsing JSON
                try:
                    data = request.get_json(force=True) or {}
                except Exception:
                    # Terceira tentativa: dados do form
                    try:
                        if request.form:
                            data = request.form.to_dict()
                        elif request.data:
                            import json
                            data = json.loads(request.data.decode('utf-8'))
                        else:
                            data = {}
                    except Exception:
                        # Usar dados padr√£o se tudo falhar
                        data = {}
        
        logger.info(f"üì° {request.method} - Dados recebidos na requisi√ß√£o: {data}")
        
        vectorizer_type = data.get('vectorizer', 'brazilian')
        clear_matches = data.get('clear_matches', False)
        enable_llm = data.get('enable_llm', True)
        max_pages = data.get('max_pages', 10)
        
        # Validar vectorizer_type
        valid_vectorizers = ['brazilian', 'hybrid', 'openai', 'voyage', 'mock']
        if vectorizer_type not in valid_vectorizers:
            return jsonify({
                'success': False,
                'error': f'vectorizer deve ser um de: {valid_vectorizers}'
            }), 400
        
        # Gerar ID √∫nico do processo
        from datetime import datetime
        process_id = f"weekly_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Executar em background
        def run_weekly_search():
            try:
                logger.info(f"üöÄ Iniciando busca semanal com processo ID: {process_id}")
                
                # Importar e configurar vectorizer
                if vectorizer_type == "brazilian":
                    from matching.vectorizers import BrazilianTextVectorizer
                    vectorizer = BrazilianTextVectorizer()
                elif vectorizer_type == "hybrid":
                    from matching.vectorizers import HybridTextVectorizer
                    vectorizer = HybridTextVectorizer()
                elif vectorizer_type == "openai":
                    from matching.vectorizers import OpenAITextVectorizer
                    vectorizer = OpenAITextVectorizer()
                elif vectorizer_type == "voyage":
                    from matching.vectorizers import VoyageAITextVectorizer
                    vectorizer = VoyageAITextVectorizer()
                else:  # mock
                    from matching.vectorizers import MockTextVectorizer
                    vectorizer = MockTextVectorizer()
                
                # Atualizar limite de p√°ginas se especificado
                if max_pages != 10:
                    from matching.pncp_api import PNCP_MAX_PAGES
                    import matching.pncp_api as pncp_api
                    pncp_api.PNCP_MAX_PAGES = max_pages
                    logger.info(f"üìÑ Limite de p√°ginas ajustado para: {max_pages}")
                
                # Executar busca semanal
                from matching.matching_engine import process_daily_bids
                
                logger.info(f"üîç Iniciando busca de licita√ß√µes da √∫ltima semana...")
                logger.info(f"ü§ñ Valida√ß√£o LLM: {'ATIVADA (QWEN 2.5:7B)' if enable_llm else 'DESATIVADA'}")
                logger.info(f"üîß Vectorizador: {vectorizer_type}")
                
                # Executar o processo (j√° modificado para buscar √∫ltima semana)
                result = process_daily_bids(vectorizer, enable_llm_validation=enable_llm)
                
                logger.info(f"‚úÖ Busca semanal conclu√≠da para processo {process_id}")
                
            except Exception as e:
                logger.error(f"‚ùå Erro na busca semanal {process_id}: {e}")
                import traceback
                logger.error(traceback.format_exc())
        
        # Iniciar thread
        thread = threading.Thread(target=run_weekly_search)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'process_id': process_id,
            'message': 'Busca semanal iniciada com valida√ß√£o LLM QWEN',
            'config': {
                'period': '√∫ltimos 7 dias',
                'llm_model': 'qwen2.5:7b' if enable_llm else 'desativado',
                'vectorizer': vectorizer_type,
                'clear_matches': clear_matches,
                'max_pages_per_uf': max_pages,
                'estimated_duration': '15-30 minutos',
                'cache': 'Redis local ativado'
            },
            'monitoring': {
                'status_endpoint': f'/api/status/weekly-search/{process_id}',
                'logs': 'Verifique logs do servidor para progresso detalhado'
            }
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao iniciar busca semanal: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@system_routes.route('/api/reevaluate-bids', methods=['POST'], strict_slashes=False)
def reevaluate_bids():
    """
    POST /api/reevaluate-bids - Reavalia√ß√£o de licita√ß√µes existentes
    
    DESCRI√á√ÉO:
    - Inicia processo de reavalia√ß√£o de matches existentes
    - Usado pelo frontend no bot√£o "Reavaliar Matches"
    - Recalcula scores de compatibilidade com novos crit√©rios
    
    PAR√ÇMETROS (Body JSON):
    - company_ids: IDs espec√≠ficos de empresas (opcional)
    - bid_ids: IDs espec√≠ficos de licita√ß√µes (opcional)
    - recalculate_all: Reprocessar todos os matches
    
    RETORNA:
    - Confirma√ß√£o de in√≠cio da reavalia√ß√£o
    - ID do processo para monitoramento
    - Quantidade estimada de registros a processar
    """
    return controller.reevaluate_bids()

# üß™ NOVA ROTA: Reprocessar licita√ß√µes existentes para testar o fix
@system_routes.route('/api/reprocess-existing-bids', methods=['POST', 'GET'], strict_slashes=False)
def reprocess_existing_bids():
    """
    POST/GET /api/reprocess-existing-bids - Reprocessar licita√ß√µes existentes com QWEN LLM
    
    DESCRI√á√ÉO:
    - Reprocessa licita√ß√µes j√° existentes no banco com valida√ß√£o LLM
    - Usado para testar corre√ß√µes no sistema de matching
    - Limpa matches anteriores e reprocessa com as novas regras
    
    PAR√ÇMETROS (opcional):
    - clear_matches: bool (default: true) - Limpar matches anteriores
    - enable_llm: bool (default: true) - Usar valida√ß√£o LLM QWEN
    - vectorizer: str (default: brazilian) - Tipo de vetorizador
    
    RETORNA:
    - process_id: ID √∫nico do processo para monitoramento
    - success: true se iniciado com sucesso
    - config: configura√ß√µes utilizadas
    """
    try:
        # Lidar com GET e POST
        if request.method == 'GET':
            data = {
                'vectorizer': request.args.get('vectorizer', 'brazilian'),
                'clear_matches': request.args.get('clear_matches', 'true').lower() == 'true',
                'enable_llm': request.args.get('enable_llm', 'true').lower() == 'true'
            }
        else:
            # POST - Tentar m√∫ltiplas formas de obter dados da requisi√ß√£o
            data = {}
            
            # Primeira tentativa: JSON normal
            try:
                data = request.get_json() or {}
            except Exception:
                # Segunda tentativa: for√ßar parsing JSON
                try:
                    data = request.get_json(force=True) or {}
                except Exception:
                    # Terceira tentativa: dados do form
                    try:
                        if request.form:
                            data = request.form.to_dict()
                        elif request.data:
                            import json
                            data = json.loads(request.data.decode('utf-8'))
                        else:
                            data = {}
                    except Exception:
                        # Usar dados padr√£o se tudo falhar
                        data = {}
        
        logger.info(f"üì° {request.method} - Dados recebidos na requisi√ß√£o: {data}")
        
        vectorizer_type = data.get('vectorizer', 'brazilian')
        clear_matches = data.get('clear_matches', True)
        enable_llm = data.get('enable_llm', True)
        
        # Gerar ID √∫nico para o processo
        process_id = f"reprocess_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Configurar vectorizador (usar imports corretos)
        if vectorizer_type == 'brazilian':
            from matching.vectorizers import BrazilianTextVectorizer
            vectorizer = BrazilianTextVectorizer()
        elif vectorizer_type == 'sentence_transformer':
            from services.sentence_transformer_service import SentenceTransformerService
            vectorizer = SentenceTransformerService()
        else:
            # Default para brazilian
            from matching.vectorizers import BrazilianTextVectorizer
            vectorizer = BrazilianTextVectorizer()
        
        # Log de in√≠cio
        logger.info(f"üîÑ Iniciando reprocessamento de licita√ß√µes existentes...")
        logger.info(f"ü§ñ Valida√ß√£o LLM: {'ATIVADA (QWEN 2.5:7B)' if enable_llm else 'DESATIVADA'}")
        logger.info(f"üîß Vectorizador: {vectorizer_type}")
        
        # Executar reprocessamento em background
        def background_reprocess():
            try:
                from matching.matching_engine import reevaluate_existing_bids
                reevaluate_existing_bids(
                    vectorizer=vectorizer,
                    clear_matches=clear_matches,
                    enable_llm_validation=enable_llm
                )
                logger.info(f"‚úÖ Reprocessamento conclu√≠do para processo {process_id}")
            except Exception as e:
                logger.error(f"‚ùå Erro no reprocessamento {process_id}: {e}")
        
        # Iniciar processo em background
        thread = threading.Thread(target=background_reprocess)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'message': 'Reprocessamento iniciado com valida√ß√£o LLM QWEN',
            'process_id': process_id,
            'config': {
                'vectorizer': vectorizer_type,
                'clear_matches': clear_matches,
                'llm_model': 'qwen2.5:7b',
                'cache': 'Redis local ativado'
            },
            'monitoring': {
                'logs': 'Verifique logs do servidor para progresso detalhado',
                'status_endpoint': f'/api/status/reprocess/{process_id}'
            }
        })
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao iniciar reprocessamento: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'message': 'Erro ao iniciar reprocessamento'
        }), 500

@system_routes.route('/api/reeval-by-date-range', methods=['POST'])
def reeval_by_date_range():
    """
    üóìÔ∏è REAVALIA√á√ÉO POR INTERVALO DE DATAS
    
    Busca licita√ß√µes em um intervalo espec√≠fico de datas e executa matching
    com valida√ß√£o LLM QWEN 2.5:7B
    
    Body JSON:
    {
        "data_inicio": "2025-06-17",  // Formato: YYYY-MM-DD
        "data_fim": "2025-06-24",     // Formato: YYYY-MM-DD
        "clear_matches": true,        // Opcional: limpar matches existentes
        "enable_llm": true,           // Opcional: ativar valida√ß√£o LLM
        "limit": 200                  // Opcional: m√°ximo de licita√ß√µes
    }
    """
    try:
        data = request.get_json() or {}
        
        # Validar par√¢metros obrigat√≥rios
        data_inicio = data.get('data_inicio')
        data_fim = data.get('data_fim')
        
        if not data_inicio or not data_fim:
            return jsonify({
                "success": False,
                "error": "Par√¢metros obrigat√≥rios: data_inicio e data_fim (formato: YYYY-MM-DD)"
            }), 400
        
        # Par√¢metros opcionais
        clear_matches = data.get('clear_matches', True)
        enable_llm = data.get('enable_llm', True)
        limit = data.get('limit', 200)
        
        # Converter para boolean de forma segura
        if isinstance(clear_matches, str):
            clear_matches = clear_matches.lower() in ['true', '1', 'yes']
        if isinstance(enable_llm, str):
            enable_llm = enable_llm.lower() in ['true', '1', 'yes']
            
        logger.info("üìÖ INICIANDO REAVALIA√á√ÉO POR INTERVALO DE DATAS")
        logger.info(f"   üìä Intervalo: {data_inicio} at√© {data_fim}")
        logger.info(f"   üìã Par√¢metros: clear_matches={clear_matches}, enable_llm={enable_llm}, limit={limit}")
        
        # Start background task
        thread = threading.Thread(
            target=run_date_range_reeval_matching,
            args=(data_inicio, data_fim, clear_matches, enable_llm, limit),
            daemon=True
        )
        thread.start()
        
        return jsonify({
            "success": True,
            "message": f"Reavalia√ß√£o de licita√ß√µes de {data_inicio} at√© {data_fim} iniciada em background",
            "details": {
                "data_inicio": data_inicio,
                "data_fim": data_fim,
                "limit": limit,
                "llm_enabled": enable_llm,
                "clear_matches": clear_matches,
                "model": "QWEN 2.5:7B"
            }
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Erro na reavalia√ß√£o por data: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

def run_date_range_reeval_matching(data_inicio: str, data_fim: str, clear_matches: bool = True, enable_llm: bool = True, limit: int = 200):
    """
    üìÖ EXECUTAR REAVALIA√á√ÉO POR INTERVALO DE DATAS
    
    Busca licita√ß√µes em um intervalo espec√≠fico e executa matching
    """
    try:
        # Usar conex√£o direta com PostgreSQL em vez do Supabase API
        from config.database import db_manager
        import time
        
        logger.info("üöÄ INICIANDO REAVALIA√á√ÉO POR INTERVALO DE DATAS")
        logger.info(f"   üìÖ Per√≠odo: {data_inicio} at√© {data_fim}")
        logger.info(f"   üìä Limite: {limit} licita√ß√µes")
        
        # 1. Buscar licita√ß√µes do intervalo usando conex√£o direta PostgreSQL
        logger.info("üìä Buscando licita√ß√µes do per√≠odo...")
        
        with db_manager.get_connection() as conn:
            with conn.cursor() as cursor:
                # Query para buscar licita√ß√µes no intervalo
                query = """
                    SELECT id, pncp_id, objeto_compra, uf, valor_total_estimado, created_at, data_publicacao
                    FROM licitacoes 
                    WHERE DATE(created_at) >= %s 
                      AND DATE(created_at) <= %s
                    ORDER BY created_at DESC 
                    LIMIT %s
                """
                
                cursor.execute(query, (data_inicio, data_fim, limit))
                licitacoes_raw = cursor.fetchall()
                
                # Converter para formato de dict
                columns = [desc[0] for desc in cursor.description]
                licitacoes = [dict(zip(columns, row)) for row in licitacoes_raw]
        
        logger.info(f"‚úÖ Encontradas {len(licitacoes)} licita√ß√µes no per√≠odo especificado")
        
        if not licitacoes:
            logger.warning(f"‚ö†Ô∏è Nenhuma licita√ß√£o encontrada entre {data_inicio} e {data_fim}")
            return
        
        # 2. Limpar matches existentes se solicitado
        if clear_matches:
            logger.info("üßπ Limpando matches existentes das licita√ß√µes do per√≠odo...")
            licitacao_ids = [lic['id'] for lic in licitacoes]
            
            with db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    # Deletar matches em lotes
                    for i in range(0, len(licitacao_ids), 50):
                        batch_ids = licitacao_ids[i:i+50]
                        placeholders = ','.join(['%s'] * len(batch_ids))
                        delete_query = f"DELETE FROM matches WHERE licitacao_id IN ({placeholders})"
                        cursor.execute(delete_query, batch_ids)
                        logger.info(f"   üóëÔ∏è Limpeza lote {i//50 + 1}: {len(batch_ids)} IDs")
                    
                    conn.commit()
            
            logger.info("‚úÖ Limpeza de matches conclu√≠da")
        
        # 3. Executar matching usando sistema existente
        from matching.matching_engine import reevaluate_existing_bids
        from matching.vectorizers import BrazilianTextVectorizer
        
        logger.info("üáßüá∑ Configurando vectorizer brasileiro...")
        vectorizer = BrazilianTextVectorizer()
        
        logger.info(f"üéØ Processando {len(licitacoes)} licita√ß√µes com QWEN 2.5:7B")
        
        # 4. Executar reavalia√ß√£o
        logger.info("üîÑ Iniciando reavalia√ß√£o com sistema otimizado...")
        tempo_inicio = time.time()
        
        resultado = reevaluate_existing_bids(
            vectorizer=vectorizer,
            clear_matches=False,  # J√° limpamos acima
            enable_llm_validation=enable_llm
        )
        
        # 5. Relat√≥rio final
        tempo_total = time.time() - tempo_inicio
        
        logger.info(f"\nüéâ REAVALIA√á√ÉO POR PER√çODO CONCLU√çDA!")
        logger.info("=" * 60)
        logger.info(f"üìÖ Per√≠odo: {data_inicio} at√© {data_fim}")
        
        if resultado:
            estatisticas = resultado.get('estatisticas', {})
            matches_encontrados = resultado.get('matches_encontrados', 0)
            
            logger.info(f"üìä ESTAT√çSTICAS FINAIS:")
            logger.info(f"   üìã Licita√ß√µes processadas: {estatisticas.get('total_processadas', 0)}")
            logger.info(f"   ‚úÖ Total de matches: {matches_encontrados}")
            logger.info(f"   ü¶ô Matches aprovados por LLM: {estatisticas.get('llm_approved', 0)}")
            logger.info(f"   ‚ùå Matches rejeitados: {estatisticas.get('llm_rejected', 0)}")
            logger.info(f"   ‚è±Ô∏è  Tempo total: {tempo_total:.1f}s")
        else:
            logger.info(f"üìä Processamento conclu√≠do em {tempo_total:.1f}s")
            
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"‚ùå ERRO CR√çTICO na reavalia√ß√£o por per√≠odo: {e}")
        import traceback
        logger.error(traceback.format_exc())

# Blueprint para exposi√ß√£o
def register_system_routes(app):
    """
    FUN√á√ÉO: register_system_routes - Registrar rotas de sistema no app Flask
    
    DESCRI√á√ÉO:
    - Fun√ß√£o utilit√°ria para registrar todas as rotas de sistema
    - Inclui logging detalhado dos endpoints registrados
    - Usado durante a inicializa√ß√£o da aplica√ß√£o
    
    PAR√ÇMETROS:
    - app: Inst√¢ncia do Flask para registrar as rotas
    
    FUNCIONALIDADE:
    - Registra o blueprint system_routes
    - Gera logs informativos sobre os endpoints
    - Confirma sucesso do registro
    """
    app.register_blueprint(system_routes)
    
    # Log dos endpoints registrados
    logger.info("‚úÖ Sistema: 7 endpoints registrados")
    logger.info("  - GET /api/health (health check)")
    logger.info("  - GET /api/status (status geral)")
    logger.info("  - GET /api/status/daily-bids (status busca)")
    logger.info("  - GET /api/status/reevaluate (status reavalia√ß√£o)")
    logger.info("  - GET /api/config/options (op√ß√µes config)")
    logger.info("  - POST /api/search-new-bids (buscar licita√ß√µes)")
    logger.info("  - POST /api/reevaluate-bids (reavaliar licita√ß√µes)") 